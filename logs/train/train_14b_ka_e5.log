[2025-01-12 22:15:03,616] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[INFO|2025-01-12 22:15:04] llamafactory.cli:157 >> Initializing distributed tasks at: 127.0.0.1:28250
W0112 22:15:05.546000 791870 site-packages/torch/distributed/run.py:793] 
W0112 22:15:05.546000 791870 site-packages/torch/distributed/run.py:793] *****************************************
W0112 22:15:05.546000 791870 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0112 22:15:05.546000 791870 site-packages/torch/distributed/run.py:793] *****************************************
[2025-01-12 22:15:07,030] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-12 22:15:07,030] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[WARNING|2025-01-12 22:15:07] llamafactory.hparams.parser:162 >> We recommend enable `upcast_layernorm` in quantized training.
[WARNING|2025-01-12 22:15:07] llamafactory.hparams.parser:162 >> `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
[INFO|2025-01-12 22:15:07] llamafactory.hparams.parser:359 >> Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16
[INFO|configuration_utils.py:677] 2025-01-12 22:15:07,844 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-12 22:15:07,844 >> Model config Qwen2Config {
  "_name_or_path": "/mnt/sda/zzh/Qwen2.5-14B-Instruct",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,844 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,845 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,845 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,845 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,845 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,845 >> loading file tokenizer_config.json
[INFO|2025-01-12 22:15:07] llamafactory.hparams.parser:359 >> Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2475] 2025-01-12 22:15:07,987 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:677] 2025-01-12 22:15:07,987 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-12 22:15:07,988 >> Model config Qwen2Config {
  "_name_or_path": "/mnt/sda/zzh/Qwen2.5-14B-Instruct",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,988 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,988 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,988 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,988 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,988 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2209] 2025-01-12 22:15:07,988 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2475] 2025-01-12 22:15:08,119 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|2025-01-12 22:15:08] llamafactory.data.template:157 >> Add <|im_end|> to stop words.
[INFO|2025-01-12 22:15:08] llamafactory.data.loader:157 >> Loading dataset entity_trans_ka.json...
[rank1]:[W112 22:15:08.705024810 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1451 examples [00:00, 38561.78 examples/s]
Converting format of dataset (num_proc=16):   0%|          | 0/1451 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1451/1451 [00:00<00:00, 10556.92 examples/s]
[rank0]:[W112 22:15:32.079917425 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Running tokenizer on dataset (num_proc=16):   0%|          | 0/1451 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 91/1451 [00:00<00:05, 258.83 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 364/1451 [00:00<00:01, 915.17 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 546/1451 [00:00<00:00, 1145.90 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 728/1451 [00:00<00:00, 1173.86 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 910/1451 [00:00<00:00, 1326.27 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1181/1451 [00:00<00:00, 1529.22 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1451/1451 [00:01<00:00, 1809.88 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1451/1451 [00:01<00:00, 1259.01 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 2610, 525, 264, 9990, 86442, 12, 22574, 14468, 7341, 11, 4486, 1492, 752, 14683, 1045, 6364, 22870, 1119, 86442, 13, 7036, 429, 279, 4396, 1102, 1265, 387, 264, 17133, 429, 7952, 304, 279, 11652, 624, 40, 686, 2968, 498, 458, 6364, 17133, 323, 264, 86442, 11652, 11, 1380, 279, 6364, 17133, 374, 279, 14468, 1102, 304, 279, 86442, 11652, 13, 358, 1366, 311, 1477, 279, 7112, 86442, 17133, 315, 279, 6364, 14468, 1102, 624, 5501, 1744, 3019, 553, 3019, 13, 151645, 198, 151644, 77091, 198, 39814, 11, 358, 646, 7789, 448, 429, 13, 5209, 3410, 279, 6364, 17133, 323, 279, 86442, 11652, 432, 7952, 304, 773, 358, 646, 10542, 279, 12159, 86442, 17133, 369, 498, 382, 5501, 3561, 279, 1946, 438, 11017, 1447, 22574, 17133, 25, 508, 4208, 6364, 17133, 921, 9499, 1775, 1103, 11652, 25, 508, 4208, 86442, 11652, 2533, 40, 3278, 1221, 3410, 279, 7112, 86442, 17133, 429, 33210, 311, 279, 6364, 14468, 1102, 13, 151645, 198, 151644, 872, 198, 22574, 17133, 25, 7513, 9652, 198, 9499, 1775, 1103, 11652, 25, 220, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 1959, 220, 146017, 146727, 145608, 146393, 147143, 145395, 146727, 148210, 145302, 145608, 145302, 145908, 220, 146017, 145608, 145989, 12, 146017, 145608, 145989, 145302, 220, 145974, 146479, 146216, 145302, 148210, 146727, 146216, 146017, 145702, 146393, 146727, 145395, 146216, 146017, 145908, 145302, 220, 145302, 146216, 145908, 147172, 145302, 147172, 145974, 147172, 145302, 13, 151645, 198, 151644, 77091, 198, 785, 2661, 6364, 17133, 7513, 9652, 646, 387, 24531, 1119, 86442, 438, 220, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 11, 323, 279, 7112, 86442, 17133, 304, 279, 2661, 11652, 1265, 387, 220, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 13, 151645, 198, 151644, 872, 198, 3973, 279, 1102, 323, 1281, 2704, 1817, 3409, 315, 279, 1102, 7952, 304, 279, 2661, 86442, 11652, 13, 151645, 198, 151644, 77091, 198, 39814, 0, 358, 614, 10067, 279, 1102, 220, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 323, 432, 2167, 7952, 304, 279, 2661, 11652, 13, 151645, 198, 151644, 872, 198, 35127, 752, 279, 1590, 1102, 2041, 1008, 4244, 13, 151645, 198, 151644, 77091, 198, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 151645]
inputs:
<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>
<|im_start|>user
You are a senior Georgian-English translation master, please help me translate some English sentences into Georgian. Note that the correct result should be a phrase that appears in the sentence.
I will give you an English phrase and a Georgian sentence, where the English phrase is the translation result in the Georgian sentence. I want to find the raw Georgian phrase of the English translation result.
Please think step by step.<|im_end|>
<|im_start|>assistant
Sure, I can assist with that. Please provide the English phrase and the Georgian sentence it appears in so I can identify the corresponding Georgian phrase for you.

Please format the input as follows:

English phrase: [insert English phrase]
Georgian sentence: [insert Georgian sentence]

I'll then provide the raw Georgian phrase that corresponds to the English translation result.<|im_end|>
<|im_start|>user
English phrase: European Commission
Georgian sentence: áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ â€” áƒ”áƒ•áƒ áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ˜áƒ¡ áƒ”áƒ áƒ—-áƒ”áƒ áƒ—áƒ˜ áƒ£áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ•áƒáƒœáƒ”áƒ¡áƒ˜ áƒ˜áƒœáƒ¡áƒ¢áƒ˜áƒ¢áƒ£áƒ¢áƒ˜.<|im_end|>
<|im_start|>assistant
The given English phrase European Commission can be translated into Georgian as áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ, and the raw Georgian phrase in the given sentence should be áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ.<|im_end|>
<|im_start|>user
Check the result and make sure each word of the result appears in the given Georgian sentence.<|im_end|>
<|im_start|>assistant
Sure! I have checked the result áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ and it really appears in the given sentence.<|im_end|>
<|im_start|>user
Give me the final result without other words.<|im_end|>
<|im_start|>assistant
áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ<|im_end|>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 39814, 11, 358, 646, 7789, 448, 429, 13, 5209, 3410, 279, 6364, 17133, 323, 279, 86442, 11652, 432, 7952, 304, 773, 358, 646, 10542, 279, 12159, 86442, 17133, 369, 498, 382, 5501, 3561, 279, 1946, 438, 11017, 1447, 22574, 17133, 25, 508, 4208, 6364, 17133, 921, 9499, 1775, 1103, 11652, 25, 508, 4208, 86442, 11652, 2533, 40, 3278, 1221, 3410, 279, 7112, 86442, 17133, 429, 33210, 311, 279, 6364, 14468, 1102, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 785, 2661, 6364, 17133, 7513, 9652, 646, 387, 24531, 1119, 86442, 438, 220, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 11, 323, 279, 7112, 86442, 17133, 304, 279, 2661, 11652, 1265, 387, 220, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 39814, 0, 358, 614, 10067, 279, 1102, 220, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 323, 432, 2167, 7952, 304, 279, 2661, 11652, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 146017, 146727, 145608, 146393, 147143, 146393, 146479, 145302, 145908, 145302, 145395, 151645]
labels:
Sure, I can assist with that. Please provide the English phrase and the Georgian sentence it appears in so I can identify the corresponding Georgian phrase for you.

Please format the input as follows:

English phrase: [insert English phrase]
Georgian sentence: [insert Georgian sentence]

I'll then provide the raw Georgian phrase that corresponds to the English translation result.<|im_end|>The given English phrase European Commission can be translated into Georgian as áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ, and the raw Georgian phrase in the given sentence should be áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ.<|im_end|>Sure! I have checked the result áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ and it really appears in the given sentence.<|im_end|>áƒ”áƒ•áƒ áƒáƒ™áƒáƒ›áƒ˜áƒ¡áƒ˜áƒ<|im_end|>
[INFO|configuration_utils.py:677] 2025-01-12 22:15:56,855 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-12 22:15:56,856 >> Model config Qwen2Config {
  "_name_or_path": "/mnt/sda/zzh/Qwen2.5-14B-Instruct",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|2025-01-12 22:15:56] llamafactory.model.model_utils.quantization:157 >> Quantizing model to 4 bit with bitsandbytes.
[INFO|modeling_utils.py:3934] 2025-01-12 22:15:56,900 >> loading weights file /mnt/sda/zzh/Qwen2.5-14B-Instruct/model.safetensors.index.json
[INFO|modeling_utils.py:1670] 2025-01-12 22:15:56,901 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1096] 2025-01-12 22:15:56,901 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|â–ˆâ–        | 1/8 [00:00<00:04,  1.69it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:01<00:03,  1.62it/s]Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:03,  1.65it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:02<00:02,  1.67it/s]Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:02<00:01,  1.70it/s]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:03<00:01,  1.72it/s]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:04<00:00,  1.73it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  2.06it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:04<00:00,  1.82it/s]
[INFO|modeling_utils.py:4800] 2025-01-12 22:16:01,427 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.

[INFO|modeling_utils.py:4808] 2025-01-12 22:16:01,427 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /mnt/sda/zzh/Qwen2.5-14B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1049] 2025-01-12 22:16:01,428 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/generation_config.json
[INFO|configuration_utils.py:1096] 2025-01-12 22:16:01,428 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.05,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

[INFO|2025-01-12 22:16:01] llamafactory.model.model_utils.checkpointing:157 >> Gradient checkpointing enabled.
[INFO|2025-01-12 22:16:01] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.
[INFO|2025-01-12 22:16:01] llamafactory.model.adapter:157 >> Upcasting trainable params to float32.
[INFO|2025-01-12 22:16:01] llamafactory.model.adapter:157 >> Fine-tuning method: LoRA
[INFO|2025-01-12 22:16:01] llamafactory.model.model_utils.misc:157 >> Found linear modules: gate_proj,down_proj,k_proj,q_proj,up_proj,o_proj,v_proj
[INFO|2025-01-12 22:16:01] llamafactory.model.loader:157 >> trainable params: 34,406,400 || all params: 14,804,440,064 || trainable%: 0.2324
[INFO|trainer.py:698] 2025-01-12 22:16:01,752 >> Using auto half precision backend
Loading checkpoint shards:  12%|â–ˆâ–        | 1/8 [00:04<00:34,  4.98s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:10<00:30,  5.05s/it]Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:15<00:25,  5.07s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:20<00:20,  5.08s/it]Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:25<00:15,  5.07s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:30<00:10,  5.07s/it]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:35<00:05,  5.08s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:37<00:00,  4.16s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:37<00:00,  4.71s/it]
[INFO|trainer.py:2313] 2025-01-12 22:16:37,711 >> ***** Running training *****
[INFO|trainer.py:2314] 2025-01-12 22:16:37,711 >>   Num examples = 1,305
[INFO|trainer.py:2315] 2025-01-12 22:16:37,711 >>   Num Epochs = 5
[INFO|trainer.py:2316] 2025-01-12 22:16:37,711 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2319] 2025-01-12 22:16:37,711 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:2320] 2025-01-12 22:16:37,711 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:2321] 2025-01-12 22:16:37,711 >>   Total optimization steps = 405
[INFO|trainer.py:2322] 2025-01-12 22:16:37,713 >>   Number of trainable parameters = 34,406,400
  0%|          | 0/405 [00:00<?, ?it/s]  0%|          | 1/405 [00:04<30:58,  4.60s/it]  0%|          | 2/405 [00:08<28:56,  4.31s/it]  1%|          | 3/405 [00:12<27:21,  4.08s/it]  1%|          | 4/405 [00:16<26:22,  3.95s/it]  1%|          | 5/405 [00:20<26:19,  3.95s/it]  1%|â–         | 6/405 [00:23<25:51,  3.89s/it]  2%|â–         | 7/405 [00:27<25:34,  3.86s/it]  2%|â–         | 8/405 [00:31<25:22,  3.83s/it]  2%|â–         | 9/405 [00:35<25:39,  3.89s/it]  2%|â–         | 10/405 [00:39<25:21,  3.85s/it]  3%|â–         | 11/405 [00:43<25:28,  3.88s/it]  3%|â–         | 12/405 [00:47<25:41,  3.92s/it]  3%|â–         | 13/405 [00:51<25:41,  3.93s/it]  3%|â–         | 14/405 [00:55<25:19,  3.89s/it]  4%|â–         | 15/405 [00:59<25:25,  3.91s/it]  4%|â–         | 16/405 [01:02<25:27,  3.93s/it]  4%|â–         | 17/405 [01:07<25:38,  3.97s/it]  4%|â–         | 18/405 [01:10<25:35,  3.97s/it]  5%|â–         | 19/405 [01:14<25:30,  3.97s/it]  5%|â–         | 20/405 [01:18<25:25,  3.96s/it]  5%|â–Œ         | 21/405 [01:23<25:41,  4.01s/it]  5%|â–Œ         | 22/405 [01:27<25:42,  4.03s/it]  6%|â–Œ         | 23/405 [01:31<25:35,  4.02s/it]  6%|â–Œ         | 24/405 [01:34<25:11,  3.97s/it]  6%|â–Œ         | 25/405 [01:38<24:40,  3.90s/it]  6%|â–‹         | 26/405 [01:42<24:33,  3.89s/it]  7%|â–‹         | 27/405 [01:46<24:35,  3.90s/it]  7%|â–‹         | 28/405 [01:50<24:33,  3.91s/it]  7%|â–‹         | 29/405 [01:54<24:28,  3.91s/it]  7%|â–‹         | 30/405 [01:58<24:16,  3.89s/it]  8%|â–Š         | 31/405 [02:02<24:50,  3.99s/it]  8%|â–Š         | 32/405 [02:06<24:36,  3.96s/it]  8%|â–Š         | 33/405 [02:10<24:34,  3.96s/it]  8%|â–Š         | 34/405 [02:14<24:08,  3.91s/it]  9%|â–Š         | 35/405 [02:17<23:48,  3.86s/it]  9%|â–‰         | 36/405 [02:21<23:40,  3.85s/it]  9%|â–‰         | 37/405 [02:25<23:38,  3.85s/it]  9%|â–‰         | 38/405 [02:29<23:26,  3.83s/it] 10%|â–‰         | 39/405 [02:33<23:42,  3.89s/it] 10%|â–‰         | 40/405 [02:37<23:46,  3.91s/it] 10%|â–ˆ         | 41/405 [02:41<23:34,  3.89s/it] 10%|â–ˆ         | 42/405 [02:44<23:24,  3.87s/it] 11%|â–ˆ         | 43/405 [02:48<23:22,  3.87s/it] 11%|â–ˆ         | 44/405 [02:52<23:16,  3.87s/it] 11%|â–ˆ         | 45/405 [02:56<23:16,  3.88s/it] 11%|â–ˆâ–        | 46/405 [03:00<23:32,  3.93s/it] 12%|â–ˆâ–        | 47/405 [03:04<23:21,  3.92s/it] 12%|â–ˆâ–        | 48/405 [03:08<23:07,  3.89s/it] 12%|â–ˆâ–        | 49/405 [03:12<22:54,  3.86s/it] 12%|â–ˆâ–        | 50/405 [03:16<22:58,  3.88s/it] 13%|â–ˆâ–        | 51/405 [03:19<22:51,  3.87s/it] 13%|â–ˆâ–        | 52/405 [03:23<22:43,  3.86s/it] 13%|â–ˆâ–        | 53/405 [03:27<22:53,  3.90s/it] 13%|â–ˆâ–        | 54/405 [03:31<23:02,  3.94s/it] 14%|â–ˆâ–        | 55/405 [03:35<23:08,  3.97s/it] 14%|â–ˆâ–        | 56/405 [03:39<22:53,  3.94s/it] 14%|â–ˆâ–        | 57/405 [03:43<23:08,  3.99s/it] 14%|â–ˆâ–        | 58/405 [03:47<23:02,  3.99s/it] 15%|â–ˆâ–        | 59/405 [03:51<22:51,  3.96s/it] 15%|â–ˆâ–        | 60/405 [03:55<22:44,  3.96s/it] 15%|â–ˆâ–Œ        | 61/405 [03:59<22:34,  3.94s/it] 15%|â–ˆâ–Œ        | 62/405 [04:03<22:11,  3.88s/it] 16%|â–ˆâ–Œ        | 63/405 [04:07<22:21,  3.92s/it] 16%|â–ˆâ–Œ        | 64/405 [04:11<22:20,  3.93s/it] 16%|â–ˆâ–Œ        | 65/405 [04:15<22:17,  3.93s/it] 16%|â–ˆâ–‹        | 66/405 [04:19<22:46,  4.03s/it] 17%|â–ˆâ–‹        | 67/405 [04:23<22:59,  4.08s/it] 17%|â–ˆâ–‹        | 68/405 [04:27<22:31,  4.01s/it] 17%|â–ˆâ–‹        | 69/405 [04:31<22:35,  4.03s/it] 17%|â–ˆâ–‹        | 70/405 [04:35<22:00,  3.94s/it] 18%|â–ˆâ–Š        | 71/405 [04:39<21:56,  3.94s/it] 18%|â–ˆâ–Š        | 72/405 [04:43<22:05,  3.98s/it] 18%|â–ˆâ–Š        | 73/405 [04:47<22:06,  4.00s/it] 18%|â–ˆâ–Š        | 74/405 [04:51<22:00,  3.99s/it] 19%|â–ˆâ–Š        | 75/405 [04:55<21:59,  4.00s/it] 19%|â–ˆâ–‰        | 76/405 [04:59<21:51,  3.99s/it] 19%|â–ˆâ–‰        | 77/405 [05:03<21:55,  4.01s/it] 19%|â–ˆâ–‰        | 78/405 [05:07<22:02,  4.04s/it] 20%|â–ˆâ–‰        | 79/405 [05:11<21:59,  4.05s/it] 20%|â–ˆâ–‰        | 80/405 [05:15<21:33,  3.98s/it] 20%|â–ˆâ–ˆ        | 81/405 [05:19<21:27,  3.97s/it][INFO|trainer.py:4117] 2025-01-12 22:22:06,980 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-12 22:22:06,980 >>   Num examples = 146
[INFO|trainer.py:4122] 2025-01-12 22:22:06,980 >>   Batch size = 1

  0%|          | 0/73 [00:00<?, ?it/s][A
  3%|â–         | 2/73 [00:00<00:05, 12.90it/s][A
  5%|â–Œ         | 4/73 [00:00<00:08,  7.95it/s][A
  7%|â–‹         | 5/73 [00:00<00:08,  7.67it/s][A
  8%|â–Š         | 6/73 [00:00<00:08,  7.52it/s][A
 10%|â–‰         | 7/73 [00:00<00:09,  7.14it/s][A
 11%|â–ˆ         | 8/73 [00:01<00:09,  7.14it/s][A
 12%|â–ˆâ–        | 9/73 [00:01<00:09,  7.01it/s][A
 14%|â–ˆâ–        | 10/73 [00:01<00:09,  6.83it/s][A
 15%|â–ˆâ–Œ        | 11/73 [00:01<00:09,  6.84it/s][A
 16%|â–ˆâ–‹        | 12/73 [00:01<00:08,  6.90it/s][A
 18%|â–ˆâ–Š        | 13/73 [00:01<00:09,  6.47it/s][A
 19%|â–ˆâ–‰        | 14/73 [00:01<00:09,  6.52it/s][A
 21%|â–ˆâ–ˆ        | 15/73 [00:02<00:08,  6.70it/s][A
 22%|â–ˆâ–ˆâ–       | 16/73 [00:02<00:08,  6.85it/s][A
 23%|â–ˆâ–ˆâ–       | 17/73 [00:02<00:08,  6.53it/s][A
 25%|â–ˆâ–ˆâ–       | 18/73 [00:02<00:08,  6.67it/s][A
 26%|â–ˆâ–ˆâ–Œ       | 19/73 [00:02<00:08,  6.51it/s][A
 27%|â–ˆâ–ˆâ–‹       | 20/73 [00:02<00:07,  6.66it/s][A
 29%|â–ˆâ–ˆâ–‰       | 21/73 [00:03<00:07,  6.85it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 22/73 [00:03<00:07,  6.91it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 23/73 [00:03<00:07,  6.56it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–      | 24/73 [00:03<00:07,  6.70it/s][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 25/73 [00:03<00:07,  6.59it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/73 [00:03<00:07,  6.70it/s][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 27/73 [00:03<00:06,  6.81it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/73 [00:04<00:06,  6.76it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 29/73 [00:04<00:06,  6.33it/s][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/73 [00:04<00:06,  6.60it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/73 [00:04<00:06,  6.61it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/73 [00:04<00:06,  6.80it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/73 [00:04<00:05,  6.91it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/73 [00:04<00:05,  6.57it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/73 [00:05<00:06,  5.93it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36/73 [00:05<00:05,  6.30it/s][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/73 [00:05<00:05,  6.54it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/73 [00:05<00:05,  6.51it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/73 [00:05<00:05,  6.45it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/73 [00:05<00:05,  6.40it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/73 [00:06<00:05,  6.13it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/73 [00:06<00:04,  6.44it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/73 [00:06<00:04,  6.65it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/73 [00:06<00:04,  6.47it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/73 [00:06<00:04,  6.43it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/73 [00:06<00:04,  6.62it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/73 [00:06<00:03,  6.80it/s][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48/73 [00:07<00:03,  6.92it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49/73 [00:07<00:03,  6.56it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/73 [00:07<00:03,  6.73it/s][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/73 [00:07<00:03,  6.80it/s][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/73 [00:07<00:03,  6.69it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/73 [00:07<00:03,  5.84it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/73 [00:08<00:03,  5.94it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 55/73 [00:08<00:03,  5.67it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 56/73 [00:08<00:02,  6.07it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 57/73 [00:08<00:02,  6.24it/s][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 58/73 [00:08<00:02,  6.51it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 59/73 [00:08<00:02,  6.67it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60/73 [00:09<00:02,  6.47it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/73 [00:09<00:01,  6.65it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/73 [00:09<00:01,  6.76it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 63/73 [00:09<00:01,  6.78it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 64/73 [00:09<00:01,  6.77it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 65/73 [00:09<00:01,  6.49it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 66/73 [00:09<00:01,  6.43it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 67/73 [00:10<00:00,  6.39it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/73 [00:10<00:00,  6.59it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/73 [00:10<00:00,  6.55it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 70/73 [00:10<00:00,  6.73it/s][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 71/73 [00:10<00:00,  6.48it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 72/73 [00:10<00:00,  6.51it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:10<00:00,  6.72it/s][A                                                
                                               [A{'eval_loss': 0.0016081709181889892, 'eval_runtime': 11.1292, 'eval_samples_per_second': 13.119, 'eval_steps_per_second': 6.559, 'epoch': 0.99}
 20%|â–ˆâ–ˆ        | 81/405 [05:30<21:27,  3.97s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:10<00:00,  6.72it/s][A
                                               [A 20%|â–ˆâ–ˆ        | 82/405 [05:34<39:20,  7.31s/it] 20%|â–ˆâ–ˆ        | 83/405 [05:38<33:40,  6.28s/it] 21%|â–ˆâ–ˆ        | 84/405 [05:42<30:07,  5.63s/it] 21%|â–ˆâ–ˆ        | 85/405 [05:46<27:40,  5.19s/it] 21%|â–ˆâ–ˆ        | 86/405 [05:50<25:27,  4.79s/it] 21%|â–ˆâ–ˆâ–       | 87/405 [05:54<24:20,  4.59s/it] 22%|â–ˆâ–ˆâ–       | 88/405 [05:58<23:11,  4.39s/it] 22%|â–ˆâ–ˆâ–       | 89/405 [06:02<22:43,  4.32s/it] 22%|â–ˆâ–ˆâ–       | 90/405 [06:06<21:56,  4.18s/it] 22%|â–ˆâ–ˆâ–       | 91/405 [06:10<21:38,  4.14s/it] 23%|â–ˆâ–ˆâ–       | 92/405 [06:14<21:15,  4.07s/it] 23%|â–ˆâ–ˆâ–       | 93/405 [06:18<20:55,  4.02s/it] 23%|â–ˆâ–ˆâ–       | 94/405 [06:22<20:41,  3.99s/it] 23%|â–ˆâ–ˆâ–       | 95/405 [06:26<20:35,  3.98s/it] 24%|â–ˆâ–ˆâ–       | 96/405 [06:30<20:21,  3.95s/it] 24%|â–ˆâ–ˆâ–       | 97/405 [06:34<20:20,  3.96s/it] 24%|â–ˆâ–ˆâ–       | 98/405 [06:37<20:08,  3.94s/it] 24%|â–ˆâ–ˆâ–       | 99/405 [06:41<20:19,  3.99s/it] 25%|â–ˆâ–ˆâ–       | 100/405 [06:45<20:10,  3.97s/it] 25%|â–ˆâ–ˆâ–       | 101/405 [06:49<19:50,  3.92s/it] 25%|â–ˆâ–ˆâ–Œ       | 102/405 [06:53<19:32,  3.87s/it] 25%|â–ˆâ–ˆâ–Œ       | 103/405 [06:57<19:36,  3.90s/it] 26%|â–ˆâ–ˆâ–Œ       | 104/405 [07:01<19:51,  3.96s/it] 26%|â–ˆâ–ˆâ–Œ       | 105/405 [07:05<19:29,  3.90s/it] 26%|â–ˆâ–ˆâ–Œ       | 106/405 [07:09<19:27,  3.90s/it] 26%|â–ˆâ–ˆâ–‹       | 107/405 [07:13<19:38,  3.96s/it] 27%|â–ˆâ–ˆâ–‹       | 108/405 [07:17<19:23,  3.92s/it] 27%|â–ˆâ–ˆâ–‹       | 109/405 [07:21<19:46,  4.01s/it] 27%|â–ˆâ–ˆâ–‹       | 110/405 [07:25<19:38,  3.99s/it] 27%|â–ˆâ–ˆâ–‹       | 111/405 [07:29<19:29,  3.98s/it] 28%|â–ˆâ–ˆâ–Š       | 112/405 [07:33<19:32,  4.00s/it] 28%|â–ˆâ–ˆâ–Š       | 113/405 [07:37<19:35,  4.02s/it] 28%|â–ˆâ–ˆâ–Š       | 114/405 [07:41<19:21,  3.99s/it] 28%|â–ˆâ–ˆâ–Š       | 115/405 [07:45<19:20,  4.00s/it] 29%|â–ˆâ–ˆâ–Š       | 116/405 [07:49<19:17,  4.00s/it] 29%|â–ˆâ–ˆâ–‰       | 117/405 [07:53<19:03,  3.97s/it] 29%|â–ˆâ–ˆâ–‰       | 118/405 [07:57<19:19,  4.04s/it] 29%|â–ˆâ–ˆâ–‰       | 119/405 [08:01<19:12,  4.03s/it] 30%|â–ˆâ–ˆâ–‰       | 120/405 [08:05<19:05,  4.02s/it] 30%|â–ˆâ–ˆâ–‰       | 121/405 [08:09<18:46,  3.97s/it] 30%|â–ˆâ–ˆâ–ˆ       | 122/405 [08:13<18:40,  3.96s/it] 30%|â–ˆâ–ˆâ–ˆ       | 123/405 [08:17<18:32,  3.95s/it] 31%|â–ˆâ–ˆâ–ˆ       | 124/405 [08:21<18:24,  3.93s/it] 31%|â–ˆâ–ˆâ–ˆ       | 125/405 [08:24<18:19,  3.93s/it] 31%|â–ˆâ–ˆâ–ˆ       | 126/405 [08:28<18:00,  3.87s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 127/405 [08:32<18:13,  3.93s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 128/405 [08:36<17:57,  3.89s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 129/405 [08:40<17:46,  3.86s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 130/405 [08:44<17:57,  3.92s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 131/405 [08:48<18:04,  3.96s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 132/405 [08:52<18:02,  3.97s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 133/405 [08:56<17:44,  3.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 134/405 [09:00<17:40,  3.91s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 135/405 [09:04<17:34,  3.91s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 136/405 [09:07<17:19,  3.87s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 137/405 [09:11<17:17,  3.87s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 138/405 [09:15<17:14,  3.87s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 139/405 [09:19<17:05,  3.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 140/405 [09:23<16:57,  3.84s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 141/405 [09:27<17:03,  3.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 142/405 [09:31<17:17,  3.95s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 143/405 [09:35<17:07,  3.92s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 144/405 [09:38<16:59,  3.91s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 145/405 [09:42<17:04,  3.94s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 146/405 [09:46<17:02,  3.95s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 147/405 [09:50<16:53,  3.93s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 148/405 [09:54<16:54,  3.95s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 149/405 [09:58<16:52,  3.95s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 150/405 [10:02<16:57,  3.99s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 151/405 [10:06<16:55,  4.00s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 152/405 [10:10<16:40,  3.95s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 153/405 [10:14<16:32,  3.94s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 154/405 [10:18<16:47,  4.02s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 155/405 [10:22<16:45,  4.02s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 156/405 [10:26<16:33,  3.99s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 157/405 [10:30<16:11,  3.92s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 158/405 [10:34<16:08,  3.92s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 159/405 [10:38<16:17,  3.97s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 160/405 [10:42<16:07,  3.95s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 161/405 [10:46<16:05,  3.96s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 162/405 [10:50<16:05,  3.97s/it][INFO|trainer.py:4117] 2025-01-12 22:27:38,609 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-12 22:27:38,609 >>   Num examples = 146
[INFO|trainer.py:4122] 2025-01-12 22:27:38,609 >>   Batch size = 1

  0%|          | 0/73 [00:00<?, ?it/s][A
  3%|â–         | 2/73 [00:00<00:05, 13.18it/s][A
  5%|â–Œ         | 4/73 [00:00<00:08,  8.05it/s][A
  7%|â–‹         | 5/73 [00:00<00:08,  7.67it/s][A
  8%|â–Š         | 6/73 [00:00<00:09,  7.44it/s][A
 10%|â–‰         | 7/73 [00:00<00:09,  7.06it/s][A
 11%|â–ˆ         | 8/73 [00:01<00:09,  7.06it/s][A
 12%|â–ˆâ–        | 9/73 [00:01<00:09,  6.95it/s][A
 14%|â–ˆâ–        | 10/73 [00:01<00:09,  6.83it/s][A
 15%|â–ˆâ–Œ        | 11/73 [00:01<00:08,  6.89it/s][A
 16%|â–ˆâ–‹        | 12/73 [00:01<00:08,  6.95it/s][A
 18%|â–ˆâ–Š        | 13/73 [00:01<00:09,  6.50it/s][A
 19%|â–ˆâ–‰        | 14/73 [00:01<00:09,  6.49it/s][A
 21%|â–ˆâ–ˆ        | 15/73 [00:02<00:08,  6.69it/s][A
 22%|â–ˆâ–ˆâ–       | 16/73 [00:02<00:08,  6.80it/s][A
 23%|â–ˆâ–ˆâ–       | 17/73 [00:02<00:08,  6.50it/s][A
 25%|â–ˆâ–ˆâ–       | 18/73 [00:02<00:08,  6.67it/s][A
 26%|â–ˆâ–ˆâ–Œ       | 19/73 [00:02<00:08,  6.51it/s][A
 27%|â–ˆâ–ˆâ–‹       | 20/73 [00:02<00:07,  6.68it/s][A
 29%|â–ˆâ–ˆâ–‰       | 21/73 [00:03<00:07,  6.86it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 22/73 [00:03<00:07,  6.97it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 23/73 [00:03<00:07,  6.58it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–      | 24/73 [00:03<00:07,  6.72it/s][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 25/73 [00:03<00:07,  6.61it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/73 [00:03<00:06,  6.73it/s][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 27/73 [00:03<00:06,  6.83it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/73 [00:04<00:06,  6.78it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 29/73 [00:04<00:06,  6.34it/s][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/73 [00:04<00:06,  6.60it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/73 [00:04<00:06,  6.61it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/73 [00:04<00:06,  6.76it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/73 [00:04<00:05,  6.87it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/73 [00:04<00:05,  6.54it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/73 [00:05<00:06,  5.92it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36/73 [00:05<00:05,  6.27it/s][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/73 [00:05<00:05,  6.54it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/73 [00:05<00:05,  6.55it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/73 [00:05<00:05,  6.48it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/73 [00:05<00:05,  6.41it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/73 [00:06<00:05,  6.13it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/73 [00:06<00:04,  6.41it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/73 [00:06<00:04,  6.56it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/73 [00:06<00:04,  6.37it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/73 [00:06<00:04,  6.34it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/73 [00:06<00:04,  6.56it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/73 [00:06<00:03,  6.74it/s][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48/73 [00:07<00:03,  6.86it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49/73 [00:07<00:03,  6.48it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/73 [00:07<00:03,  6.63it/s][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/73 [00:07<00:03,  6.72it/s][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/73 [00:07<00:03,  6.61it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/73 [00:07<00:03,  5.83it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/73 [00:08<00:03,  5.93it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 55/73 [00:08<00:03,  5.66it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 56/73 [00:08<00:02,  6.06it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 57/73 [00:08<00:02,  6.24it/s][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 58/73 [00:08<00:02,  6.46it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 59/73 [00:08<00:02,  6.61it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60/73 [00:09<00:02,  6.39it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/73 [00:09<00:01,  6.57it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/73 [00:09<00:01,  6.68it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 63/73 [00:09<00:01,  6.73it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 64/73 [00:09<00:01,  6.73it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 65/73 [00:09<00:01,  6.44it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 66/73 [00:09<00:01,  6.39it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 67/73 [00:10<00:00,  6.36it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/73 [00:10<00:00,  6.61it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/73 [00:10<00:00,  6.58it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 70/73 [00:10<00:00,  6.75it/s][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 71/73 [00:10<00:00,  6.46it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 72/73 [00:10<00:00,  6.50it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.70it/s][A                                                 
                                               [A{'eval_loss': 0.0007305827457457781, 'eval_runtime': 11.2187, 'eval_samples_per_second': 13.014, 'eval_steps_per_second': 6.507, 'epoch': 1.99}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 162/405 [11:02<16:05,  3.97s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.70it/s][A
                                               [A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 163/405 [11:05<29:26,  7.30s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 164/405 [11:09<25:24,  6.33s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 165/405 [11:13<22:16,  5.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 166/405 [11:17<20:14,  5.08s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 167/405 [11:21<18:45,  4.73s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 168/405 [11:25<17:42,  4.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 169/405 [11:29<16:59,  4.32s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 170/405 [11:33<16:32,  4.23s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 171/405 [11:36<16:04,  4.12s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 172/405 [11:41<16:01,  4.13s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 173/405 [11:44<15:38,  4.04s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 174/405 [11:48<15:32,  4.04s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 175/405 [11:52<15:20,  4.00s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 176/405 [11:56<15:23,  4.03s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 177/405 [12:00<15:10,  3.99s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 178/405 [12:04<14:54,  3.94s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 179/405 [12:08<14:45,  3.92s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 180/405 [12:12<14:43,  3.93s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 181/405 [12:16<14:38,  3.92s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 182/405 [12:20<14:30,  3.90s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 183/405 [12:24<14:23,  3.89s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 184/405 [12:27<14:16,  3.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 185/405 [12:31<14:14,  3.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 186/405 [12:35<14:03,  3.85s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 187/405 [12:39<13:56,  3.84s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 188/405 [12:43<14:01,  3.88s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 189/405 [12:47<14:12,  3.95s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 190/405 [12:51<13:59,  3.90s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 191/405 [12:55<13:57,  3.92s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 192/405 [12:59<14:03,  3.96s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 193/405 [13:03<13:53,  3.93s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 194/405 [13:07<13:50,  3.94s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 195/405 [13:11<13:45,  3.93s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 196/405 [13:15<13:42,  3.93s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 197/405 [13:19<14:12,  4.10s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 198/405 [13:23<14:06,  4.09s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 199/405 [13:27<13:50,  4.03s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 200/405 [13:31<13:34,  3.97s/it]                                                 {'loss': 0.1954, 'grad_norm': 0.0060335383750498295, 'learning_rate': 5.986030470739811e-05, 'epoch': 2.46}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 200/405 [13:31<13:34,  3.97s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 201/405 [13:35<13:46,  4.05s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 202/405 [13:39<13:32,  4.00s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 203/405 [13:43<13:22,  3.97s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 204/405 [13:47<13:22,  3.99s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 205/405 [13:51<13:20,  4.00s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 206/405 [13:55<13:28,  4.06s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 207/405 [13:59<13:09,  3.99s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 208/405 [14:03<13:03,  3.98s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 209/405 [14:07<12:54,  3.95s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 210/405 [14:11<12:43,  3.91s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 211/405 [14:15<12:44,  3.94s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 212/405 [14:18<12:32,  3.90s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 213/405 [14:22<12:37,  3.95s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 214/405 [14:26<12:36,  3.96s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 215/405 [14:31<12:58,  4.10s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 216/405 [14:35<12:47,  4.06s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 217/405 [14:39<12:28,  3.98s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 218/405 [14:43<12:27,  4.00s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 219/405 [14:47<12:36,  4.07s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 220/405 [14:51<12:32,  4.07s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 221/405 [14:55<12:22,  4.03s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 222/405 [14:59<12:12,  4.00s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 223/405 [15:03<11:56,  3.94s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 224/405 [15:07<11:53,  3.94s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 225/405 [15:10<11:46,  3.93s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 226/405 [15:15<11:50,  3.97s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 227/405 [15:18<11:40,  3.94s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 228/405 [15:22<11:32,  3.91s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 229/405 [15:27<11:46,  4.01s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 230/405 [15:31<11:43,  4.02s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 231/405 [15:34<11:35,  4.00s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 232/405 [15:39<11:38,  4.04s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 233/405 [15:43<11:37,  4.06s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 234/405 [15:47<11:21,  3.99s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 235/405 [15:51<11:28,  4.05s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 236/405 [15:55<11:10,  3.97s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 237/405 [15:59<11:07,  3.98s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 238/405 [16:03<11:05,  3.98s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 239/405 [16:06<10:55,  3.95s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 240/405 [16:11<11:01,  4.01s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 241/405 [16:14<10:46,  3.94s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 242/405 [16:18<10:42,  3.94s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 243/405 [16:22<10:34,  3.91s/it][INFO|trainer.py:4117] 2025-01-12 22:33:11,325 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-12 22:33:11,325 >>   Num examples = 146
[INFO|trainer.py:4122] 2025-01-12 22:33:11,325 >>   Batch size = 1

  0%|          | 0/73 [00:00<?, ?it/s][A
  3%|â–         | 2/73 [00:00<00:05, 12.65it/s][A
  5%|â–Œ         | 4/73 [00:00<00:08,  7.80it/s][A
  7%|â–‹         | 5/73 [00:00<00:09,  7.53it/s][A
  8%|â–Š         | 6/73 [00:00<00:09,  7.39it/s][A
 10%|â–‰         | 7/73 [00:00<00:09,  7.03it/s][A
 11%|â–ˆ         | 8/73 [00:01<00:09,  7.01it/s][A
 12%|â–ˆâ–        | 9/73 [00:01<00:09,  6.91it/s][A
 14%|â–ˆâ–        | 10/73 [00:01<00:09,  6.76it/s][A
 15%|â–ˆâ–Œ        | 11/73 [00:01<00:09,  6.80it/s][A
 16%|â–ˆâ–‹        | 12/73 [00:01<00:08,  6.92it/s][A
 18%|â–ˆâ–Š        | 13/73 [00:01<00:09,  6.48it/s][A
 19%|â–ˆâ–‰        | 14/73 [00:01<00:09,  6.51it/s][A
 21%|â–ˆâ–ˆ        | 15/73 [00:02<00:08,  6.72it/s][A
 22%|â–ˆâ–ˆâ–       | 16/73 [00:02<00:08,  6.85it/s][A
 23%|â–ˆâ–ˆâ–       | 17/73 [00:02<00:08,  6.56it/s][A
 25%|â–ˆâ–ˆâ–       | 18/73 [00:02<00:08,  6.66it/s][A
 26%|â–ˆâ–ˆâ–Œ       | 19/73 [00:02<00:08,  6.51it/s][A
 27%|â–ˆâ–ˆâ–‹       | 20/73 [00:02<00:07,  6.67it/s][A
 29%|â–ˆâ–ˆâ–‰       | 21/73 [00:03<00:07,  6.86it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 22/73 [00:03<00:07,  6.95it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 23/73 [00:03<00:07,  6.61it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–      | 24/73 [00:03<00:07,  6.73it/s][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 25/73 [00:03<00:07,  6.60it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/73 [00:03<00:07,  6.69it/s][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 27/73 [00:03<00:06,  6.77it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/73 [00:04<00:06,  6.73it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 29/73 [00:04<00:06,  6.31it/s][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/73 [00:04<00:06,  6.57it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/73 [00:04<00:06,  6.59it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/73 [00:04<00:06,  6.76it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/73 [00:04<00:05,  6.85it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/73 [00:04<00:05,  6.50it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/73 [00:05<00:06,  5.89it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36/73 [00:05<00:05,  6.27it/s][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/73 [00:05<00:05,  6.50it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/73 [00:05<00:05,  6.49it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/73 [00:05<00:05,  6.44it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/73 [00:05<00:05,  6.39it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/73 [00:06<00:05,  6.12it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/73 [00:06<00:04,  6.42it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/73 [00:06<00:04,  6.63it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/73 [00:06<00:04,  6.45it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/73 [00:06<00:04,  6.41it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/73 [00:06<00:04,  6.61it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/73 [00:07<00:03,  6.78it/s][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48/73 [00:07<00:03,  6.87it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49/73 [00:07<00:03,  6.49it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/73 [00:07<00:03,  6.65it/s][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/73 [00:07<00:03,  6.72it/s][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/73 [00:07<00:03,  6.60it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/73 [00:07<00:03,  5.79it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/73 [00:08<00:03,  5.90it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 55/73 [00:08<00:03,  5.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 56/73 [00:08<00:02,  6.05it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 57/73 [00:08<00:02,  6.23it/s][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 58/73 [00:08<00:02,  6.51it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 59/73 [00:08<00:02,  6.68it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60/73 [00:09<00:02,  6.46it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/73 [00:09<00:01,  6.63it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/73 [00:09<00:01,  6.77it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 63/73 [00:09<00:01,  6.82it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 64/73 [00:09<00:01,  6.80it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 65/73 [00:09<00:01,  6.50it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 66/73 [00:09<00:01,  6.43it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 67/73 [00:10<00:00,  6.39it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/73 [00:10<00:00,  6.61it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/73 [00:10<00:00,  6.55it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 70/73 [00:10<00:00,  6.72it/s][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 71/73 [00:10<00:00,  6.44it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 72/73 [00:10<00:00,  6.48it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.67it/s][A                                                 
                                               [A{'eval_loss': 0.0004476456670090556, 'eval_runtime': 11.1746, 'eval_samples_per_second': 13.065, 'eval_steps_per_second': 6.533, 'epoch': 2.99}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 243/405 [16:35<10:34,  3.91s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.67it/s][A
                                               [A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 244/405 [16:37<19:35,  7.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 245/405 [16:41<16:46,  6.29s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 246/405 [16:45<15:00,  5.67s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 247/405 [16:49<13:35,  5.16s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 248/405 [16:54<12:44,  4.87s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 249/405 [16:58<12:01,  4.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 250/405 [17:02<11:32,  4.47s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 251/405 [17:06<11:03,  4.31s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 252/405 [17:10<10:37,  4.17s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 253/405 [17:14<10:36,  4.19s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 254/405 [17:18<10:15,  4.08s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 255/405 [17:22<10:11,  4.07s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 256/405 [17:26<09:59,  4.03s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 257/405 [17:29<09:50,  3.99s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 258/405 [17:34<09:47,  4.00s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 259/405 [17:37<09:35,  3.94s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 260/405 [17:41<09:36,  3.98s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 261/405 [17:45<09:34,  3.99s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 262/405 [17:49<09:25,  3.96s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 263/405 [17:53<09:26,  3.99s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 264/405 [17:57<09:19,  3.97s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 265/405 [18:01<09:17,  3.99s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 266/405 [18:05<09:07,  3.94s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 267/405 [18:09<09:07,  3.96s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 268/405 [18:13<08:57,  3.92s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 269/405 [18:17<08:54,  3.93s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 270/405 [18:21<08:57,  3.98s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 271/405 [18:25<08:51,  3.96s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 272/405 [18:29<08:45,  3.95s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 273/405 [18:33<08:44,  3.98s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 274/405 [18:37<08:42,  3.99s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 275/405 [18:41<08:51,  4.09s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 276/405 [18:45<08:39,  4.02s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 277/405 [18:49<08:31,  3.99s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 278/405 [18:53<08:20,  3.94s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 279/405 [18:57<08:12,  3.91s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 280/405 [19:01<08:11,  3.94s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 281/405 [19:05<08:08,  3.94s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 282/405 [19:08<07:57,  3.88s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 283/405 [19:12<07:57,  3.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 284/405 [19:16<07:59,  3.97s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 285/405 [19:20<07:51,  3.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 286/405 [19:24<07:41,  3.88s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 287/405 [19:28<07:48,  3.97s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 288/405 [19:32<07:44,  3.97s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 289/405 [19:36<07:36,  3.93s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 290/405 [19:40<07:35,  3.96s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 291/405 [19:44<07:28,  3.94s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 292/405 [19:48<07:28,  3.97s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 293/405 [19:52<07:26,  3.98s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 294/405 [19:56<07:16,  3.93s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 295/405 [20:00<07:11,  3.92s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 296/405 [20:04<07:04,  3.90s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 297/405 [20:08<07:06,  3.95s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 298/405 [20:12<07:02,  3.95s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 299/405 [20:16<06:59,  3.95s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 300/405 [20:19<06:53,  3.94s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 301/405 [20:23<06:51,  3.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 302/405 [20:27<06:47,  3.95s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 303/405 [20:31<06:39,  3.91s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 304/405 [20:35<06:32,  3.89s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 305/405 [20:39<06:33,  3.94s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 306/405 [20:43<06:31,  3.95s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 307/405 [20:47<06:26,  3.94s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 308/405 [20:51<06:25,  3.98s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 309/405 [20:55<06:23,  3.99s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 310/405 [20:59<06:15,  3.95s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 311/405 [21:03<06:09,  3.93s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 312/405 [21:07<06:03,  3.91s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 313/405 [21:10<05:55,  3.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 314/405 [21:14<05:53,  3.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 315/405 [21:18<05:49,  3.89s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 316/405 [21:22<05:47,  3.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 317/405 [21:26<05:47,  3.94s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 318/405 [21:30<05:43,  3.95s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 319/405 [21:34<05:40,  3.96s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 320/405 [21:38<05:37,  3.97s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 321/405 [21:42<05:35,  3.99s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 322/405 [21:46<05:25,  3.92s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 323/405 [21:50<05:22,  3.94s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 324/405 [21:54<05:16,  3.91s/it][INFO|trainer.py:4117] 2025-01-12 22:38:43,802 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-12 22:38:43,802 >>   Num examples = 146
[INFO|trainer.py:4122] 2025-01-12 22:38:43,802 >>   Batch size = 1

  0%|          | 0/73 [00:00<?, ?it/s][A
  3%|â–         | 2/73 [00:00<00:05, 13.00it/s][A
  5%|â–Œ         | 4/73 [00:00<00:08,  7.90it/s][A
  7%|â–‹         | 5/73 [00:00<00:08,  7.60it/s][A
  8%|â–Š         | 6/73 [00:00<00:09,  7.44it/s][A
 10%|â–‰         | 7/73 [00:00<00:09,  7.07it/s][A
 11%|â–ˆ         | 8/73 [00:01<00:09,  7.07it/s][A
 12%|â–ˆâ–        | 9/73 [00:01<00:09,  6.96it/s][A
 14%|â–ˆâ–        | 10/73 [00:01<00:09,  6.82it/s][A
 15%|â–ˆâ–Œ        | 11/73 [00:01<00:09,  6.84it/s][A
 16%|â–ˆâ–‹        | 12/73 [00:01<00:08,  6.90it/s][A
 18%|â–ˆâ–Š        | 13/73 [00:01<00:09,  6.47it/s][A
 19%|â–ˆâ–‰        | 14/73 [00:01<00:09,  6.47it/s][A
 21%|â–ˆâ–ˆ        | 15/73 [00:02<00:08,  6.65it/s][A
 22%|â–ˆâ–ˆâ–       | 16/73 [00:02<00:08,  6.78it/s][A
 23%|â–ˆâ–ˆâ–       | 17/73 [00:02<00:08,  6.50it/s][A
 25%|â–ˆâ–ˆâ–       | 18/73 [00:02<00:08,  6.66it/s][A
 26%|â–ˆâ–ˆâ–Œ       | 19/73 [00:02<00:08,  6.51it/s][A
 27%|â–ˆâ–ˆâ–‹       | 20/73 [00:02<00:07,  6.64it/s][A
 29%|â–ˆâ–ˆâ–‰       | 21/73 [00:03<00:07,  6.84it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 22/73 [00:03<00:07,  6.88it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 23/73 [00:03<00:07,  6.50it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–      | 24/73 [00:03<00:07,  6.66it/s][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 25/73 [00:03<00:07,  6.57it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/73 [00:03<00:07,  6.70it/s][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 27/73 [00:03<00:06,  6.81it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/73 [00:04<00:06,  6.76it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 29/73 [00:04<00:06,  6.33it/s][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/73 [00:04<00:06,  6.60it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/73 [00:04<00:06,  6.61it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/73 [00:04<00:06,  6.80it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/73 [00:04<00:05,  6.92it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/73 [00:04<00:05,  6.56it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/73 [00:05<00:06,  5.93it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36/73 [00:05<00:05,  6.28it/s][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/73 [00:05<00:05,  6.55it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/73 [00:05<00:05,  6.55it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/73 [00:05<00:05,  6.49it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/73 [00:05<00:05,  6.42it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/73 [00:06<00:05,  6.14it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/73 [00:06<00:04,  6.43it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/73 [00:06<00:04,  6.59it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/73 [00:06<00:04,  6.40it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/73 [00:06<00:04,  6.38it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/73 [00:06<00:04,  6.59it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/73 [00:06<00:03,  6.77it/s][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48/73 [00:07<00:03,  6.89it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49/73 [00:07<00:03,  6.50it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/73 [00:07<00:03,  6.65it/s][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/73 [00:07<00:03,  6.72it/s][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/73 [00:07<00:03,  6.61it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/73 [00:07<00:03,  5.79it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/73 [00:08<00:03,  5.90it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 55/73 [00:08<00:03,  5.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 56/73 [00:08<00:02,  6.05it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 57/73 [00:08<00:02,  6.24it/s][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 58/73 [00:08<00:02,  6.51it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 59/73 [00:08<00:02,  6.66it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60/73 [00:09<00:02,  6.41it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/73 [00:09<00:01,  6.59it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/73 [00:09<00:01,  6.73it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 63/73 [00:09<00:01,  6.80it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 64/73 [00:09<00:01,  6.78it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 65/73 [00:09<00:01,  6.47it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 66/73 [00:09<00:01,  6.41it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 67/73 [00:10<00:00,  6.37it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/73 [00:10<00:00,  6.61it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/73 [00:10<00:00,  6.59it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 70/73 [00:10<00:00,  6.75it/s][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 71/73 [00:10<00:00,  6.45it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 72/73 [00:10<00:00,  6.49it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.65it/s][A                                                 
                                               [A{'eval_loss': 0.0004214464861433953, 'eval_runtime': 11.1714, 'eval_samples_per_second': 13.069, 'eval_steps_per_second': 6.535, 'epoch': 3.99}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 324/405 [22:07<05:16,  3.91s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.65it/s][A
                                               [A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 325/405 [22:09<09:46,  7.33s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 326/405 [22:13<08:18,  6.31s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 327/405 [22:17<07:16,  5.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 328/405 [22:21<06:34,  5.12s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 329/405 [22:25<06:04,  4.80s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 330/405 [22:29<05:39,  4.52s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 331/405 [22:33<05:23,  4.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 332/405 [22:37<05:11,  4.26s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 333/405 [22:41<05:02,  4.20s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 334/405 [22:45<04:54,  4.14s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 335/405 [22:49<04:44,  4.07s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 336/405 [22:53<04:39,  4.05s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 337/405 [22:57<04:33,  4.02s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 338/405 [23:01<04:32,  4.06s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 339/405 [23:05<04:25,  4.03s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 340/405 [23:09<04:18,  3.98s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 341/405 [23:13<04:11,  3.93s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 342/405 [23:17<04:07,  3.93s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 343/405 [23:21<04:05,  3.96s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 344/405 [23:25<04:00,  3.94s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 345/405 [23:29<03:57,  3.96s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 346/405 [23:32<03:51,  3.93s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 347/405 [23:36<03:50,  3.97s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 348/405 [23:41<03:49,  4.03s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 349/405 [23:45<03:48,  4.08s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 350/405 [23:49<03:41,  4.02s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 351/405 [23:53<03:38,  4.04s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 352/405 [23:57<03:30,  3.97s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 353/405 [24:00<03:25,  3.95s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 354/405 [24:04<03:21,  3.95s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 355/405 [24:08<03:15,  3.91s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 356/405 [24:12<03:14,  3.96s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 357/405 [24:16<03:09,  3.96s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 358/405 [24:20<03:05,  3.94s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 359/405 [24:24<03:01,  3.95s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 360/405 [24:28<02:56,  3.93s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 361/405 [24:32<02:55,  4.00s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 362/405 [24:36<02:48,  3.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 363/405 [24:40<02:47,  3.99s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 364/405 [24:44<02:42,  3.98s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 365/405 [24:48<02:39,  3.99s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 366/405 [24:52<02:34,  3.97s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 367/405 [24:56<02:31,  3.98s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 368/405 [25:00<02:26,  3.96s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 369/405 [25:04<02:22,  3.95s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 370/405 [25:08<02:21,  4.04s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 371/405 [25:12<02:15,  3.97s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 372/405 [25:16<02:12,  4.00s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 373/405 [25:20<02:07,  3.98s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 374/405 [25:24<02:02,  3.96s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 375/405 [25:28<01:58,  3.97s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 376/405 [25:32<01:56,  4.00s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 377/405 [25:36<01:51,  3.98s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 378/405 [25:40<01:47,  3.99s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 379/405 [25:44<01:43,  3.98s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 380/405 [25:48<01:39,  3.97s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 381/405 [25:52<01:36,  4.03s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 382/405 [25:56<01:32,  4.02s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 383/405 [26:00<01:28,  4.03s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 384/405 [26:04<01:23,  3.98s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 385/405 [26:08<01:18,  3.94s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 386/405 [26:12<01:15,  3.97s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 387/405 [26:16<01:12,  4.02s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 388/405 [26:20<01:07,  3.95s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 389/405 [26:24<01:03,  3.95s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 390/405 [26:28<00:59,  3.97s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 391/405 [26:31<00:55,  3.95s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 392/405 [26:35<00:51,  3.97s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 393/405 [26:39<00:47,  3.93s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 394/405 [26:43<00:42,  3.91s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 395/405 [26:47<00:38,  3.90s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 396/405 [26:51<00:34,  3.88s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 397/405 [26:55<00:31,  3.89s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 398/405 [26:59<00:27,  3.93s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 399/405 [27:03<00:23,  3.92s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 400/405 [27:06<00:19,  3.88s/it]                                                 {'loss': 0.0002, 'grad_norm': 0.0009569362155161798, 'learning_rate': 4.6548918743033464e-08, 'epoch': 4.92}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 400/405 [27:07<00:19,  3.88s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 401/405 [27:11<00:15,  3.93s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 402/405 [27:15<00:12,  4.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 403/405 [27:19<00:08,  4.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 404/405 [27:23<00:03,  3.97s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 405/405 [27:26<00:00,  3.92s/it][INFO|trainer.py:3801] 2025-01-12 22:44:14,254 >> Saving model checkpoint to saves/qwen-14b-ka-e5/lora/sft/checkpoint-405
[INFO|configuration_utils.py:677] 2025-01-12 22:44:14,274 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-12 22:44:14,274 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2646] 2025-01-12 22:44:14,397 >> tokenizer config file saved in saves/qwen-14b-ka-e5/lora/sft/checkpoint-405/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2025-01-12 22:44:14,397 >> Special tokens file saved in saves/qwen-14b-ka-e5/lora/sft/checkpoint-405/special_tokens_map.json
[INFO|trainer.py:4117] 2025-01-12 22:44:14,639 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-12 22:44:14,639 >>   Num examples = 146
[INFO|trainer.py:4122] 2025-01-12 22:44:14,639 >>   Batch size = 1

  0%|          | 0/73 [00:00<?, ?it/s][A
  3%|â–         | 2/73 [00:00<00:05, 13.29it/s][A
  5%|â–Œ         | 4/73 [00:00<00:08,  8.08it/s][A
  7%|â–‹         | 5/73 [00:00<00:08,  7.75it/s][A
  8%|â–Š         | 6/73 [00:00<00:08,  7.56it/s][A
 10%|â–‰         | 7/73 [00:00<00:09,  7.13it/s][A
 11%|â–ˆ         | 8/73 [00:01<00:09,  7.08it/s][A
 12%|â–ˆâ–        | 9/73 [00:01<00:09,  6.96it/s][A
 14%|â–ˆâ–        | 10/73 [00:01<00:09,  6.77it/s][A
 15%|â–ˆâ–Œ        | 11/73 [00:01<00:09,  6.81it/s][A
 16%|â–ˆâ–‹        | 12/73 [00:01<00:08,  6.89it/s][A
 18%|â–ˆâ–Š        | 13/73 [00:01<00:09,  6.46it/s][A
 19%|â–ˆâ–‰        | 14/73 [00:01<00:09,  6.50it/s][A
 21%|â–ˆâ–ˆ        | 15/73 [00:02<00:08,  6.72it/s][A
 22%|â–ˆâ–ˆâ–       | 16/73 [00:02<00:08,  6.85it/s][A
 23%|â–ˆâ–ˆâ–       | 17/73 [00:02<00:08,  6.57it/s][A
 25%|â–ˆâ–ˆâ–       | 18/73 [00:02<00:08,  6.75it/s][A
 26%|â–ˆâ–ˆâ–Œ       | 19/73 [00:02<00:08,  6.56it/s][A
 27%|â–ˆâ–ˆâ–‹       | 20/73 [00:02<00:07,  6.74it/s][A
 29%|â–ˆâ–ˆâ–‰       | 21/73 [00:02<00:07,  6.91it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 22/73 [00:03<00:07,  6.99it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 23/73 [00:03<00:07,  6.61it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–      | 24/73 [00:03<00:07,  6.71it/s][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 25/73 [00:03<00:07,  6.56it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/73 [00:03<00:07,  6.67it/s][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 27/73 [00:03<00:06,  6.79it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/73 [00:04<00:06,  6.75it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 29/73 [00:04<00:06,  6.32it/s][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/73 [00:04<00:06,  6.57it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/73 [00:04<00:06,  6.59it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/73 [00:04<00:06,  6.77it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/73 [00:04<00:05,  6.90it/s][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/73 [00:04<00:05,  6.56it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/73 [00:05<00:06,  5.93it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36/73 [00:05<00:05,  6.30it/s][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/73 [00:05<00:05,  6.56it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/73 [00:05<00:05,  6.56it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/73 [00:05<00:05,  6.47it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/73 [00:05<00:05,  6.40it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/73 [00:06<00:05,  6.14it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/73 [00:06<00:04,  6.43it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/73 [00:06<00:04,  6.59it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/73 [00:06<00:04,  6.37it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/73 [00:06<00:04,  6.34it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/73 [00:06<00:04,  6.55it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/73 [00:06<00:03,  6.73it/s][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48/73 [00:07<00:03,  6.85it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49/73 [00:07<00:03,  6.48it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/73 [00:07<00:03,  6.64it/s][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/73 [00:07<00:03,  6.71it/s][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/73 [00:07<00:03,  6.61it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/73 [00:07<00:03,  5.78it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/73 [00:08<00:03,  5.90it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 55/73 [00:08<00:03,  5.64it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 56/73 [00:08<00:02,  6.04it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 57/73 [00:08<00:02,  6.22it/s][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 58/73 [00:08<00:02,  6.48it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 59/73 [00:08<00:02,  6.67it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60/73 [00:09<00:02,  6.45it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/73 [00:09<00:01,  6.66it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/73 [00:09<00:01,  6.81it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 63/73 [00:09<00:01,  6.86it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 64/73 [00:09<00:01,  6.82it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 65/73 [00:09<00:01,  6.49it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 66/73 [00:09<00:01,  6.43it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 67/73 [00:10<00:00,  6.39it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/73 [00:10<00:00,  6.56it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/73 [00:10<00:00,  6.48it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 70/73 [00:10<00:00,  6.64it/s][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 71/73 [00:10<00:00,  6.39it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 72/73 [00:10<00:00,  6.44it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.60it/s][A                                                 
                                               [A{'eval_loss': 0.0004119648365303874, 'eval_runtime': 11.1561, 'eval_samples_per_second': 13.087, 'eval_steps_per_second': 6.544, 'epoch': 4.99}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 405/405 [27:38<00:00,  3.92s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:11<00:00,  6.60it/s][A
                                               [A[INFO|trainer.py:2584] 2025-01-12 22:44:25,795 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 1668.0818, 'train_samples_per_second': 3.912, 'train_steps_per_second': 0.243, 'train_loss': 0.09660711190404578, 'epoch': 4.99}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 405/405 [27:38<00:00,  3.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 405/405 [27:38<00:00,  4.10s/it]
[INFO|trainer.py:3801] 2025-01-12 22:44:25,796 >> Saving model checkpoint to saves/qwen-14b-ka-e5/lora/sft
[INFO|configuration_utils.py:677] 2025-01-12 22:44:25,816 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-12 22:44:25,816 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2646] 2025-01-12 22:44:25,936 >> tokenizer config file saved in saves/qwen-14b-ka-e5/lora/sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2025-01-12 22:44:25,936 >> Special tokens file saved in saves/qwen-14b-ka-e5/lora/sft/special_tokens_map.json
***** train metrics *****
  epoch                    =      4.9862
  total_flos               = 197182524GF
  train_loss               =      0.0966
  train_runtime            =  0:27:48.08
  train_samples_per_second =       3.912
  train_steps_per_second   =       0.243
Figure saved at: saves/qwen-14b-ka-e5/lora/sft/training_loss.png
Figure saved at: saves/qwen-14b-ka-e5/lora/sft/training_eval_loss.png
[WARNING|2025-01-12 22:44:26] llamafactory.extras.ploting:162 >> No metric eval_accuracy to plot.
[INFO|trainer.py:4117] 2025-01-12 22:44:26,105 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-12 22:44:26,105 >>   Num examples = 146
[INFO|trainer.py:4122] 2025-01-12 22:44:26,105 >>   Batch size = 1
  0%|          | 0/73 [00:00<?, ?it/s]  3%|â–         | 2/73 [00:00<00:05, 13.21it/s]  5%|â–Œ         | 4/73 [00:00<00:08,  8.12it/s]  7%|â–‹         | 5/73 [00:00<00:08,  7.79it/s]  8%|â–Š         | 6/73 [00:00<00:08,  7.63it/s] 10%|â–‰         | 7/73 [00:00<00:09,  7.24it/s] 11%|â–ˆ         | 8/73 [00:01<00:09,  7.20it/s] 12%|â–ˆâ–        | 9/73 [00:01<00:09,  7.04it/s] 14%|â–ˆâ–        | 10/73 [00:01<00:09,  6.86it/s] 15%|â–ˆâ–Œ        | 11/73 [00:01<00:09,  6.86it/s] 16%|â–ˆâ–‹        | 12/73 [00:01<00:08,  6.91it/s] 18%|â–ˆâ–Š        | 13/73 [00:01<00:09,  6.48it/s] 19%|â–ˆâ–‰        | 14/73 [00:01<00:09,  6.51it/s] 21%|â–ˆâ–ˆ        | 15/73 [00:02<00:08,  6.73it/s] 22%|â–ˆâ–ˆâ–       | 16/73 [00:02<00:08,  6.84it/s] 23%|â–ˆâ–ˆâ–       | 17/73 [00:02<00:08,  6.53it/s] 25%|â–ˆâ–ˆâ–       | 18/73 [00:02<00:08,  6.71it/s] 26%|â–ˆâ–ˆâ–Œ       | 19/73 [00:02<00:08,  6.54it/s] 27%|â–ˆâ–ˆâ–‹       | 20/73 [00:02<00:07,  6.74it/s] 29%|â–ˆâ–ˆâ–‰       | 21/73 [00:02<00:07,  6.91it/s] 30%|â–ˆâ–ˆâ–ˆ       | 22/73 [00:03<00:07,  6.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 23/73 [00:03<00:07,  6.60it/s] 33%|â–ˆâ–ˆâ–ˆâ–      | 24/73 [00:03<00:07,  6.73it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 25/73 [00:03<00:07,  6.62it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/73 [00:03<00:06,  6.73it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 27/73 [00:03<00:06,  6.82it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 28/73 [00:04<00:06,  6.77it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 29/73 [00:04<00:06,  6.34it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/73 [00:04<00:06,  6.61it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/73 [00:04<00:06,  6.62it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/73 [00:04<00:06,  6.79it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/73 [00:04<00:05,  6.88it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/73 [00:04<00:05,  6.55it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/73 [00:05<00:06,  5.92it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 36/73 [00:05<00:05,  6.29it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 37/73 [00:05<00:05,  6.53it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/73 [00:05<00:05,  6.52it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/73 [00:05<00:05,  6.47it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 40/73 [00:05<00:05,  6.40it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 41/73 [00:06<00:05,  6.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/73 [00:06<00:04,  6.42it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/73 [00:06<00:04,  6.56it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/73 [00:06<00:04,  6.37it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/73 [00:06<00:04,  6.37it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/73 [00:06<00:04,  6.59it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 47/73 [00:06<00:03,  6.77it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 48/73 [00:07<00:03,  6.89it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 49/73 [00:07<00:03,  6.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 50/73 [00:07<00:03,  6.67it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 51/73 [00:07<00:03,  6.74it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 52/73 [00:07<00:03,  6.62it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/73 [00:07<00:03,  5.80it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/73 [00:08<00:03,  5.91it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 55/73 [00:08<00:03,  5.65it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 56/73 [00:08<00:02,  6.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 57/73 [00:08<00:02,  6.23it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 58/73 [00:08<00:02,  6.45it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 59/73 [00:08<00:02,  6.65it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60/73 [00:09<00:02,  6.42it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/73 [00:09<00:01,  6.60it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 62/73 [00:09<00:01,  6.71it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 63/73 [00:09<00:01,  6.74it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 64/73 [00:09<00:01,  6.74it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 65/73 [00:09<00:01,  6.42it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 66/73 [00:09<00:01,  6.38it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 67/73 [00:10<00:00,  6.36it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/73 [00:10<00:00,  6.58it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/73 [00:10<00:00,  6.53it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 70/73 [00:10<00:00,  6.73it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 71/73 [00:10<00:00,  6.44it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 72/73 [00:10<00:00,  6.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:10<00:00,  6.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:10<00:00,  6.64it/s]
***** eval metrics *****
  epoch                   =     4.9862
  eval_loss               =     0.0004
  eval_runtime            = 0:00:11.13
  eval_samples_per_second =     13.107
  eval_steps_per_second   =      6.553
[INFO|modelcard.py:449] 2025-01-12 22:44:37,245 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
[rank0]:[W112 22:44:37.081380948 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
