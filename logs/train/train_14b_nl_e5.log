[2025-01-06 20:31:16,398] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[INFO|2025-01-06 20:31:17] llamafactory.cli:157 >> Initializing distributed tasks at: 127.0.0.1:28868
W0106 20:31:18.312000 3926912 site-packages/torch/distributed/run.py:793] 
W0106 20:31:18.312000 3926912 site-packages/torch/distributed/run.py:793] *****************************************
W0106 20:31:18.312000 3926912 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0106 20:31:18.312000 3926912 site-packages/torch/distributed/run.py:793] *****************************************
[2025-01-06 20:31:19,805] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-01-06 20:31:19,805] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[WARNING|2025-01-06 20:31:20] llamafactory.hparams.parser:162 >> We recommend enable `upcast_layernorm` in quantized training.
[WARNING|2025-01-06 20:31:20] llamafactory.hparams.parser:162 >> `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
[INFO|2025-01-06 20:31:20] llamafactory.hparams.parser:359 >> Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16
[INFO|configuration_utils.py:677] 2025-01-06 20:31:20,613 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-06 20:31:20,613 >> Model config Qwen2Config {
  "_name_or_path": "/mnt/sda/zzh/Qwen2.5-14B-Instruct",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,614 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,614 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,614 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,614 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,614 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,614 >> loading file tokenizer_config.json
[INFO|2025-01-06 20:31:20] llamafactory.hparams.parser:359 >> Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2475] 2025-01-06 20:31:20,746 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:677] 2025-01-06 20:31:20,746 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-06 20:31:20,746 >> Model config Qwen2Config {
  "_name_or_path": "/mnt/sda/zzh/Qwen2.5-14B-Instruct",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,747 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,747 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,747 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,747 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,747 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2209] 2025-01-06 20:31:20,747 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2475] 2025-01-06 20:31:20,879 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|2025-01-06 20:31:20] llamafactory.data.template:157 >> Add <|im_end|> to stop words.
[INFO|2025-01-06 20:31:20] llamafactory.data.loader:157 >> Loading dataset entity_trans_nl.json...
[rank1]:[W106 20:31:20.467796538 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.

Generating train split: 0 examples [00:00, ? examples/s]
Generating train split: 1797 examples [00:00, 63339.11 examples/s]

Converting format of dataset (num_proc=16):   0%|          | 0/1797 [00:00<?, ? examples/s]
Converting format of dataset (num_proc=16): 100%|██████████| 1797/1797 [00:00<00:00, 11215.00 examples/s]
[rank0]:[W106 20:31:45.796168003 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.

Running tokenizer on dataset (num_proc=16):   0%|          | 0/1797 [00:00<?, ? examples/s]
Running tokenizer on dataset (num_proc=16):   6%|▋         | 113/1797 [00:00<00:05, 326.12 examples/s]
Running tokenizer on dataset (num_proc=16):  19%|█▉        | 339/1797 [00:00<00:01, 848.14 examples/s]
Running tokenizer on dataset (num_proc=16):  31%|███▏      | 565/1797 [00:00<00:01, 1183.54 examples/s]
Running tokenizer on dataset (num_proc=16):  44%|████▍     | 789/1797 [00:00<00:00, 1419.16 examples/s]
Running tokenizer on dataset (num_proc=16):  63%|██████▎   | 1125/1797 [00:00<00:00, 1698.36 examples/s]
Running tokenizer on dataset (num_proc=16):  81%|████████▏ | 1461/1797 [00:01<00:00, 1844.21 examples/s]
Running tokenizer on dataset (num_proc=16): 100%|██████████| 1797/1797 [00:01<00:00, 2116.08 examples/s]
Running tokenizer on dataset (num_proc=16): 100%|██████████| 1797/1797 [00:01<00:00, 1485.69 examples/s]
training example:
input_ids:
[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 2610, 525, 264, 9990, 23234, 12, 22574, 14468, 7341, 11, 4486, 1492, 752, 14683, 1045, 6364, 22870, 1119, 23234, 13, 7036, 429, 279, 4396, 1102, 1265, 387, 264, 17133, 429, 7952, 304, 279, 11652, 624, 40, 686, 2968, 498, 458, 6364, 17133, 323, 264, 23234, 11652, 11, 1380, 279, 6364, 17133, 374, 279, 14468, 1102, 304, 279, 23234, 11652, 13, 358, 1366, 311, 1477, 279, 7112, 23234, 17133, 315, 279, 6364, 14468, 1102, 624, 5501, 1744, 3019, 553, 3019, 13, 151645, 198, 151644, 77091, 198, 39814, 11, 358, 646, 7789, 448, 429, 13, 5209, 3410, 279, 6364, 17133, 323, 279, 23234, 11652, 432, 7952, 304, 773, 358, 646, 10542, 279, 12159, 23234, 17133, 369, 498, 382, 5501, 3561, 279, 1946, 438, 11017, 1447, 22574, 17133, 25, 508, 4208, 6364, 17133, 921, 35, 14061, 11652, 25, 508, 4208, 23234, 11652, 2533, 40, 3278, 1221, 3410, 279, 7112, 23234, 17133, 429, 33210, 311, 279, 6364, 14468, 1102, 13, 151645, 198, 151644, 872, 198, 22574, 17133, 25, 9812, 198, 35, 14061, 11652, 25, 1581, 67015, 2367, 1230, 645, 320, 38807, 8, 374, 8352, 24302, 220, 17, 22, 67015, 2367, 4268, 268, 1850, 64, 437, 2793, 268, 423, 7053, 13, 151645, 198, 151644, 77091, 198, 785, 2661, 6364, 17133, 9812, 646, 387, 24531, 1119, 23234, 438, 67015, 2367, 1230, 645, 11, 323, 279, 7112, 23234, 17133, 304, 279, 2661, 11652, 1265, 387, 67015, 2367, 1230, 645, 13, 151645, 198, 151644, 872, 198, 3973, 279, 1102, 323, 1281, 2704, 1817, 3409, 315, 279, 1102, 7952, 304, 279, 2661, 23234, 11652, 13, 151645, 198, 151644, 77091, 198, 39814, 0, 358, 614, 10067, 279, 1102, 67015, 2367, 1230, 645, 323, 432, 2167, 7952, 304, 279, 2661, 11652, 13, 151645, 198, 151644, 872, 198, 35127, 752, 279, 1590, 1102, 2041, 1008, 4244, 13, 151645, 198, 151644, 77091, 198, 54118, 887, 2367, 1230, 645, 151645]
inputs:
<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>
<|im_start|>user
You are a senior Dutch-English translation master, please help me translate some English sentences into Dutch. Note that the correct result should be a phrase that appears in the sentence.
I will give you an English phrase and a Dutch sentence, where the English phrase is the translation result in the Dutch sentence. I want to find the raw Dutch phrase of the English translation result.
Please think step by step.<|im_end|>
<|im_start|>assistant
Sure, I can assist with that. Please provide the English phrase and the Dutch sentence it appears in so I can identify the corresponding Dutch phrase for you.

Please format the input as follows:

English phrase: [insert English phrase]
Dutch sentence: [insert Dutch sentence]

I'll then provide the raw Dutch phrase that corresponds to the English translation result.<|im_end|>
<|im_start|>user
English phrase: EU
Dutch sentence: De Europese Unie (EU) is een uit 27 Europese landen bestaand statenverband.<|im_end|>
<|im_start|>assistant
The given English phrase EU can be translated into Dutch as Europese Unie, and the raw Dutch phrase in the given sentence should be Europese Unie.<|im_end|>
<|im_start|>user
Check the result and make sure each word of the result appears in the given Dutch sentence.<|im_end|>
<|im_start|>assistant
Sure! I have checked the result Europese Unie and it really appears in the given sentence.<|im_end|>
<|im_start|>user
Give me the final result without other words.<|im_end|>
<|im_start|>assistant
Europese Unie<|im_end|>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 39814, 11, 358, 646, 7789, 448, 429, 13, 5209, 3410, 279, 6364, 17133, 323, 279, 23234, 11652, 432, 7952, 304, 773, 358, 646, 10542, 279, 12159, 23234, 17133, 369, 498, 382, 5501, 3561, 279, 1946, 438, 11017, 1447, 22574, 17133, 25, 508, 4208, 6364, 17133, 921, 35, 14061, 11652, 25, 508, 4208, 23234, 11652, 2533, 40, 3278, 1221, 3410, 279, 7112, 23234, 17133, 429, 33210, 311, 279, 6364, 14468, 1102, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 785, 2661, 6364, 17133, 9812, 646, 387, 24531, 1119, 23234, 438, 67015, 2367, 1230, 645, 11, 323, 279, 7112, 23234, 17133, 304, 279, 2661, 11652, 1265, 387, 67015, 2367, 1230, 645, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 39814, 0, 358, 614, 10067, 279, 1102, 67015, 2367, 1230, 645, 323, 432, 2167, 7952, 304, 279, 2661, 11652, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 54118, 887, 2367, 1230, 645, 151645]
labels:
Sure, I can assist with that. Please provide the English phrase and the Dutch sentence it appears in so I can identify the corresponding Dutch phrase for you.

Please format the input as follows:

English phrase: [insert English phrase]
Dutch sentence: [insert Dutch sentence]

I'll then provide the raw Dutch phrase that corresponds to the English translation result.<|im_end|>The given English phrase EU can be translated into Dutch as Europese Unie, and the raw Dutch phrase in the given sentence should be Europese Unie.<|im_end|>Sure! I have checked the result Europese Unie and it really appears in the given sentence.<|im_end|>Europese Unie<|im_end|>
[INFO|configuration_utils.py:677] 2025-01-06 20:32:09,486 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-06 20:32:09,487 >> Model config Qwen2Config {
  "_name_or_path": "/mnt/sda/zzh/Qwen2.5-14B-Instruct",
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|2025-01-06 20:32:09] llamafactory.model.model_utils.quantization:157 >> Quantizing model to 4 bit with bitsandbytes.
[INFO|modeling_utils.py:3934] 2025-01-06 20:32:09,530 >> loading weights file /mnt/sda/zzh/Qwen2.5-14B-Instruct/model.safetensors.index.json
[INFO|modeling_utils.py:1670] 2025-01-06 20:32:09,531 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1096] 2025-01-06 20:32:09,531 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}


Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]
Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:04,  1.73it/s]
Loading checkpoint shards:  25%|██▌       | 2/8 [00:01<00:03,  1.59it/s]
Loading checkpoint shards:  38%|███▊      | 3/8 [00:01<00:03,  1.64it/s]
Loading checkpoint shards:  50%|█████     | 4/8 [00:02<00:02,  1.67it/s]
Loading checkpoint shards:  62%|██████▎   | 5/8 [00:02<00:01,  1.70it/s]
Loading checkpoint shards:  75%|███████▌  | 6/8 [00:03<00:01,  1.73it/s]
Loading checkpoint shards:  88%|████████▊ | 7/8 [00:04<00:00,  1.72it/s]
Loading checkpoint shards: 100%|██████████| 8/8 [00:04<00:00,  2.05it/s]
Loading checkpoint shards: 100%|██████████| 8/8 [00:04<00:00,  1.81it/s]
[INFO|modeling_utils.py:4800] 2025-01-06 20:32:14,068 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.

[INFO|modeling_utils.py:4808] 2025-01-06 20:32:14,068 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at /mnt/sda/zzh/Qwen2.5-14B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1049] 2025-01-06 20:32:14,069 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/generation_config.json
[INFO|configuration_utils.py:1096] 2025-01-06 20:32:14,069 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.05,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}

[INFO|2025-01-06 20:32:14] llamafactory.model.model_utils.checkpointing:157 >> Gradient checkpointing enabled.
[INFO|2025-01-06 20:32:14] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.
[INFO|2025-01-06 20:32:14] llamafactory.model.adapter:157 >> Upcasting trainable params to float32.
[INFO|2025-01-06 20:32:14] llamafactory.model.adapter:157 >> Fine-tuning method: LoRA
[INFO|2025-01-06 20:32:14] llamafactory.model.model_utils.misc:157 >> Found linear modules: q_proj,k_proj,gate_proj,v_proj,down_proj,o_proj,up_proj
[INFO|2025-01-06 20:32:14] llamafactory.model.loader:157 >> trainable params: 34,406,400 || all params: 14,804,440,064 || trainable%: 0.2324
[INFO|trainer.py:698] 2025-01-06 20:32:14,419 >> Using auto half precision backend

Loading checkpoint shards:  12%|█▎        | 1/8 [00:04<00:34,  4.96s/it]
Loading checkpoint shards:  25%|██▌       | 2/8 [00:10<00:30,  5.04s/it]
Loading checkpoint shards:  38%|███▊      | 3/8 [00:15<00:25,  5.06s/it]
Loading checkpoint shards:  50%|█████     | 4/8 [00:20<00:20,  5.07s/it]
Loading checkpoint shards:  62%|██████▎   | 5/8 [00:25<00:15,  5.06s/it]
Loading checkpoint shards:  75%|███████▌  | 6/8 [00:30<00:10,  5.07s/it]
Loading checkpoint shards:  88%|████████▊ | 7/8 [00:35<00:05,  5.07s/it]
Loading checkpoint shards: 100%|██████████| 8/8 [00:37<00:00,  4.16s/it]
Loading checkpoint shards: 100%|██████████| 8/8 [00:37<00:00,  4.70s/it]
[INFO|trainer.py:2313] 2025-01-06 20:32:50,307 >> ***** Running training *****
[INFO|trainer.py:2314] 2025-01-06 20:32:50,307 >>   Num examples = 1,617
[INFO|trainer.py:2315] 2025-01-06 20:32:50,307 >>   Num Epochs = 5
[INFO|trainer.py:2316] 2025-01-06 20:32:50,307 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2319] 2025-01-06 20:32:50,307 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:2320] 2025-01-06 20:32:50,307 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:2321] 2025-01-06 20:32:50,307 >>   Total optimization steps = 505
[INFO|trainer.py:2322] 2025-01-06 20:32:50,309 >>   Number of trainable parameters = 34,406,400

  0%|          | 0/505 [00:00<?, ?it/s]
  0%|          | 1/505 [00:04<34:37,  4.12s/it]
  0%|          | 2/505 [00:07<32:38,  3.89s/it]
  1%|          | 3/505 [00:11<31:54,  3.81s/it]
  1%|          | 4/505 [00:15<31:32,  3.78s/it]
  1%|          | 5/505 [00:19<31:26,  3.77s/it]
  1%|          | 6/505 [00:22<31:42,  3.81s/it]
  1%|▏         | 7/505 [00:26<31:16,  3.77s/it]
  2%|▏         | 8/505 [00:30<30:57,  3.74s/it]
  2%|▏         | 9/505 [00:34<31:09,  3.77s/it]
  2%|▏         | 10/505 [00:37<31:02,  3.76s/it]
  2%|▏         | 11/505 [00:41<30:48,  3.74s/it]
  2%|▏         | 12/505 [00:45<31:03,  3.78s/it]
  3%|▎         | 13/505 [00:49<30:59,  3.78s/it]
  3%|▎         | 14/505 [00:52<30:52,  3.77s/it]
  3%|▎         | 15/505 [00:56<30:37,  3.75s/it]
  3%|▎         | 16/505 [01:00<30:33,  3.75s/it]
  3%|▎         | 17/505 [01:04<30:18,  3.73s/it]
  4%|▎         | 18/505 [01:07<30:17,  3.73s/it]
  4%|▍         | 19/505 [01:11<30:12,  3.73s/it]
  4%|▍         | 20/505 [01:15<30:14,  3.74s/it]
  4%|▍         | 21/505 [01:19<30:10,  3.74s/it]
  4%|▍         | 22/505 [01:22<30:05,  3.74s/it]
  5%|▍         | 23/505 [01:26<30:02,  3.74s/it]
  5%|▍         | 24/505 [01:30<29:57,  3.74s/it]
  5%|▍         | 25/505 [01:34<29:59,  3.75s/it]
  5%|▌         | 26/505 [01:37<29:55,  3.75s/it]
  5%|▌         | 27/505 [01:41<30:01,  3.77s/it]
  6%|▌         | 28/505 [01:45<29:47,  3.75s/it]
  6%|▌         | 29/505 [01:49<29:54,  3.77s/it]
  6%|▌         | 30/505 [01:52<29:53,  3.78s/it]
  6%|▌         | 31/505 [01:56<29:46,  3.77s/it]
  6%|▋         | 32/505 [02:00<29:45,  3.77s/it]
  7%|▋         | 33/505 [02:04<29:49,  3.79s/it]
  7%|▋         | 34/505 [02:08<29:51,  3.80s/it]
  7%|▋         | 35/505 [02:11<29:32,  3.77s/it]
  7%|▋         | 36/505 [02:15<29:20,  3.75s/it]
  7%|▋         | 37/505 [02:19<29:23,  3.77s/it]
  8%|▊         | 38/505 [02:23<29:13,  3.76s/it]
  8%|▊         | 39/505 [02:26<29:08,  3.75s/it]
  8%|▊         | 40/505 [02:30<29:01,  3.75s/it]
  8%|▊         | 41/505 [02:34<28:53,  3.74s/it]
  8%|▊         | 42/505 [02:37<28:48,  3.73s/it]
  9%|▊         | 43/505 [02:41<28:44,  3.73s/it]
  9%|▊         | 44/505 [02:45<29:04,  3.78s/it]
  9%|▉         | 45/505 [02:49<28:55,  3.77s/it]
  9%|▉         | 46/505 [02:53<28:41,  3.75s/it]
  9%|▉         | 47/505 [02:56<28:40,  3.76s/it]
 10%|▉         | 48/505 [03:00<28:36,  3.76s/it]
 10%|▉         | 49/505 [03:04<28:41,  3.78s/it]
 10%|▉         | 50/505 [03:08<28:30,  3.76s/it]
 10%|█         | 51/505 [03:11<28:30,  3.77s/it]
 10%|█         | 52/505 [03:15<28:35,  3.79s/it]
 10%|█         | 53/505 [03:19<28:28,  3.78s/it]
 11%|█         | 54/505 [03:23<28:32,  3.80s/it]
 11%|█         | 55/505 [03:27<28:22,  3.78s/it]
 11%|█         | 56/505 [03:30<28:22,  3.79s/it]
 11%|█▏        | 57/505 [03:34<28:16,  3.79s/it]
 11%|█▏        | 58/505 [03:38<28:03,  3.77s/it]
 12%|█▏        | 59/505 [03:42<28:07,  3.78s/it]
 12%|█▏        | 60/505 [03:46<28:01,  3.78s/it]
 12%|█▏        | 61/505 [03:49<27:54,  3.77s/it]
 12%|█▏        | 62/505 [03:53<27:47,  3.76s/it]
 12%|█▏        | 63/505 [03:57<27:58,  3.80s/it]
 13%|█▎        | 64/505 [04:01<27:55,  3.80s/it]
 13%|█▎        | 65/505 [04:04<27:43,  3.78s/it]
 13%|█▎        | 66/505 [04:08<27:37,  3.78s/it]
 13%|█▎        | 67/505 [04:12<27:37,  3.79s/it]
 13%|█▎        | 68/505 [04:16<27:28,  3.77s/it]
 14%|█▎        | 69/505 [04:20<27:24,  3.77s/it]
 14%|█▍        | 70/505 [04:23<27:14,  3.76s/it]
 14%|█▍        | 71/505 [04:27<27:17,  3.77s/it]
 14%|█▍        | 72/505 [04:31<27:06,  3.76s/it]
 14%|█▍        | 73/505 [04:35<27:11,  3.78s/it]
 15%|█▍        | 74/505 [04:38<27:04,  3.77s/it]
 15%|█▍        | 75/505 [04:42<27:27,  3.83s/it]
 15%|█▌        | 76/505 [04:46<27:11,  3.80s/it]
 15%|█▌        | 77/505 [04:50<26:58,  3.78s/it]
 15%|█▌        | 78/505 [04:54<26:58,  3.79s/it]
 16%|█▌        | 79/505 [04:57<26:39,  3.76s/it]
 16%|█▌        | 80/505 [05:01<26:33,  3.75s/it]
 16%|█▌        | 81/505 [05:05<26:38,  3.77s/it]
 16%|█▌        | 82/505 [05:09<26:38,  3.78s/it]
 16%|█▋        | 83/505 [05:12<26:37,  3.79s/it]
 17%|█▋        | 84/505 [05:16<26:27,  3.77s/it]
 17%|█▋        | 85/505 [05:20<26:17,  3.75s/it]
 17%|█▋        | 86/505 [05:24<26:13,  3.75s/it]
 17%|█▋        | 87/505 [05:27<26:11,  3.76s/it]
 17%|█▋        | 88/505 [05:31<26:15,  3.78s/it]
 18%|█▊        | 89/505 [05:35<26:10,  3.77s/it]
 18%|█▊        | 90/505 [05:39<26:12,  3.79s/it]
 18%|█▊        | 91/505 [05:43<25:58,  3.77s/it]
 18%|█▊        | 92/505 [05:46<25:49,  3.75s/it]
 18%|█▊        | 93/505 [05:50<25:49,  3.76s/it]
 19%|█▊        | 94/505 [05:54<25:49,  3.77s/it]
 19%|█▉        | 95/505 [05:58<25:40,  3.76s/it]
 19%|█▉        | 96/505 [06:01<25:47,  3.78s/it]
 19%|█▉        | 97/505 [06:05<25:47,  3.79s/it]
 19%|█▉        | 98/505 [06:09<25:43,  3.79s/it]
 20%|█▉        | 99/505 [06:13<25:35,  3.78s/it]
 20%|█▉        | 100/505 [06:16<25:25,  3.77s/it]
 20%|██        | 101/505 [06:20<25:26,  3.78s/it][INFO|trainer.py:4117] 2025-01-06 20:39:21,078 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-06 20:39:21,078 >>   Num examples = 180
[INFO|trainer.py:4122] 2025-01-06 20:39:21,078 >>   Batch size = 1


  0%|          | 0/90 [00:00<?, ?it/s][A

  2%|▏         | 2/90 [00:00<00:06, 13.07it/s][A

  4%|▍         | 4/90 [00:00<00:10,  8.58it/s][A

  6%|▌         | 5/90 [00:00<00:10,  8.13it/s][A

  7%|▋         | 6/90 [00:00<00:10,  7.78it/s][A

  8%|▊         | 7/90 [00:00<00:10,  7.55it/s][A

  9%|▉         | 8/90 [00:01<00:11,  7.36it/s][A

 10%|█         | 9/90 [00:01<00:11,  7.18it/s][A

 11%|█         | 10/90 [00:01<00:11,  7.11it/s][A

 12%|█▏        | 11/90 [00:01<00:11,  6.97it/s][A

 13%|█▎        | 12/90 [00:01<00:11,  6.77it/s][A

 14%|█▍        | 13/90 [00:01<00:11,  6.86it/s][A

 16%|█▌        | 14/90 [00:01<00:10,  6.95it/s][A

 17%|█▋        | 15/90 [00:02<00:10,  6.86it/s][A

 18%|█▊        | 16/90 [00:02<00:10,  6.92it/s][A

 19%|█▉        | 17/90 [00:02<00:10,  6.90it/s][A

 20%|██        | 18/90 [00:02<00:10,  6.88it/s][A

 21%|██        | 19/90 [00:02<00:10,  6.92it/s][A

 22%|██▏       | 20/90 [00:02<00:10,  6.95it/s][A

 23%|██▎       | 21/90 [00:02<00:09,  6.94it/s][A

 24%|██▍       | 22/90 [00:03<00:10,  6.73it/s][A

 26%|██▌       | 23/90 [00:03<00:09,  6.83it/s][A

 27%|██▋       | 24/90 [00:03<00:09,  6.87it/s][A

 28%|██▊       | 25/90 [00:03<00:09,  6.75it/s][A

 29%|██▉       | 26/90 [00:03<00:09,  6.61it/s][A

 30%|███       | 27/90 [00:03<00:09,  6.92it/s][A

 31%|███       | 28/90 [00:03<00:09,  6.78it/s][A

 32%|███▏      | 29/90 [00:04<00:09,  6.60it/s][A

 33%|███▎      | 30/90 [00:04<00:08,  6.67it/s][A

 34%|███▍      | 31/90 [00:04<00:08,  6.77it/s][A

 36%|███▌      | 32/90 [00:04<00:08,  6.62it/s][A

 37%|███▋      | 33/90 [00:04<00:08,  6.80it/s][A

 38%|███▊      | 34/90 [00:04<00:08,  6.89it/s][A

 39%|███▉      | 35/90 [00:04<00:07,  6.95it/s][A

 40%|████      | 36/90 [00:05<00:07,  6.95it/s][A

 41%|████      | 37/90 [00:05<00:07,  6.96it/s][A

 42%|████▏     | 38/90 [00:05<00:07,  6.93it/s][A

 43%|████▎     | 39/90 [00:05<00:07,  6.94it/s][A

 44%|████▍     | 40/90 [00:05<00:07,  6.96it/s][A

 46%|████▌     | 41/90 [00:05<00:07,  6.95it/s][A

 47%|████▋     | 42/90 [00:05<00:06,  6.96it/s][A

 48%|████▊     | 43/90 [00:06<00:06,  6.96it/s][A

 49%|████▉     | 44/90 [00:06<00:06,  6.97it/s][A

 50%|█████     | 45/90 [00:06<00:06,  6.99it/s][A

 51%|█████     | 46/90 [00:06<00:06,  6.97it/s][A

 52%|█████▏    | 47/90 [00:06<00:06,  6.75it/s][A

 53%|█████▎    | 48/90 [00:06<00:06,  6.85it/s][A

 54%|█████▍    | 49/90 [00:06<00:05,  6.89it/s][A

 56%|█████▌    | 50/90 [00:07<00:05,  6.92it/s][A

 57%|█████▋    | 51/90 [00:07<00:05,  6.89it/s][A

 58%|█████▊    | 52/90 [00:07<00:05,  6.89it/s][A

 59%|█████▉    | 53/90 [00:07<00:05,  6.91it/s][A

 60%|██████    | 54/90 [00:07<00:05,  6.93it/s][A

 61%|██████    | 55/90 [00:07<00:05,  6.93it/s][A

 62%|██████▏   | 56/90 [00:08<00:04,  6.95it/s][A

 63%|██████▎   | 57/90 [00:08<00:04,  6.94it/s][A

 64%|██████▍   | 58/90 [00:08<00:04,  7.00it/s][A

 66%|██████▌   | 59/90 [00:08<00:04,  6.64it/s][A

 67%|██████▋   | 60/90 [00:08<00:04,  6.74it/s][A

 68%|██████▊   | 61/90 [00:08<00:04,  6.71it/s][A

 69%|██████▉   | 62/90 [00:08<00:04,  6.83it/s][A

 70%|███████   | 63/90 [00:09<00:03,  6.77it/s][A

 71%|███████   | 64/90 [00:09<00:03,  6.63it/s][A

 72%|███████▏  | 65/90 [00:09<00:03,  6.76it/s][A

 73%|███████▎  | 66/90 [00:09<00:03,  6.82it/s][A

 74%|███████▍  | 67/90 [00:09<00:03,  6.60it/s][A

 76%|███████▌  | 68/90 [00:09<00:03,  6.71it/s][A

 77%|███████▋  | 69/90 [00:09<00:03,  6.83it/s][A

 78%|███████▊  | 70/90 [00:10<00:02,  6.89it/s][A

 79%|███████▉  | 71/90 [00:10<00:02,  6.83it/s][A

 80%|████████  | 72/90 [00:10<00:02,  6.87it/s][A

 81%|████████  | 73/90 [00:10<00:02,  6.66it/s][A

 82%|████████▏ | 74/90 [00:10<00:02,  6.74it/s][A

 83%|████████▎ | 75/90 [00:10<00:02,  6.71it/s][A

 84%|████████▍ | 76/90 [00:10<00:02,  6.59it/s][A

 86%|████████▌ | 77/90 [00:11<00:01,  6.71it/s][A

 87%|████████▋ | 78/90 [00:11<00:01,  6.71it/s][A

 88%|████████▊ | 79/90 [00:11<00:01,  6.76it/s][A

 89%|████████▉ | 80/90 [00:11<00:01,  6.79it/s][A

 90%|█████████ | 81/90 [00:11<00:01,  6.86it/s][A

 91%|█████████ | 82/90 [00:11<00:01,  6.89it/s][A

 92%|█████████▏| 83/90 [00:11<00:01,  6.90it/s][A

 93%|█████████▎| 84/90 [00:12<00:00,  6.90it/s][A

 94%|█████████▍| 85/90 [00:12<00:00,  6.89it/s][A

 96%|█████████▌| 86/90 [00:12<00:00,  6.82it/s][A

 97%|█████████▋| 87/90 [00:12<00:00,  6.64it/s][A

 98%|█████████▊| 88/90 [00:12<00:00,  6.74it/s][A

 99%|█████████▉| 89/90 [00:12<00:00,  6.78it/s][A

100%|██████████| 90/90 [00:13<00:00,  6.81it/s][A
                                                 

                                               
[A{'eval_loss': 0.002698749303817749, 'eval_runtime': 13.2053, 'eval_samples_per_second': 13.631, 'eval_steps_per_second': 6.815, 'epoch': 1.0}

 20%|██        | 101/505 [06:34<25:26,  3.78s/it]

100%|██████████| 90/90 [00:13<00:00,  6.81it/s][A

                                               [A
 20%|██        | 102/505 [06:37<52:00,  7.74s/it]
 20%|██        | 103/505 [06:41<43:58,  6.56s/it]
 21%|██        | 104/505 [06:45<38:01,  5.69s/it]
 21%|██        | 105/505 [06:49<34:07,  5.12s/it]
 21%|██        | 106/505 [06:52<31:16,  4.70s/it]
 21%|██        | 107/505 [06:56<29:36,  4.46s/it]
 21%|██▏       | 108/505 [07:00<28:11,  4.26s/it]
 22%|██▏       | 109/505 [07:04<27:07,  4.11s/it]
 22%|██▏       | 110/505 [07:07<26:21,  4.00s/it]
 22%|██▏       | 111/505 [07:11<25:56,  3.95s/it]
 22%|██▏       | 112/505 [07:15<25:38,  3.91s/it]
 22%|██▏       | 113/505 [07:19<25:18,  3.87s/it]
 23%|██▎       | 114/505 [07:23<25:01,  3.84s/it]
 23%|██▎       | 115/505 [07:27<25:06,  3.86s/it]
 23%|██▎       | 116/505 [07:30<24:44,  3.81s/it]
 23%|██▎       | 117/505 [07:34<24:49,  3.84s/it]
 23%|██▎       | 118/505 [07:38<24:27,  3.79s/it]
 24%|██▎       | 119/505 [07:42<24:17,  3.78s/it]
 24%|██▍       | 120/505 [07:45<24:12,  3.77s/it]
 24%|██▍       | 121/505 [07:49<24:23,  3.81s/it]
 24%|██▍       | 122/505 [07:53<24:13,  3.79s/it]
 24%|██▍       | 123/505 [07:57<24:04,  3.78s/it]
 25%|██▍       | 124/505 [08:01<23:59,  3.78s/it]
 25%|██▍       | 125/505 [08:04<23:51,  3.77s/it]
 25%|██▍       | 126/505 [08:08<23:48,  3.77s/it]
 25%|██▌       | 127/505 [08:12<23:46,  3.78s/it]
 25%|██▌       | 128/505 [08:16<23:41,  3.77s/it]
 26%|██▌       | 129/505 [08:19<23:38,  3.77s/it]
 26%|██▌       | 130/505 [08:23<23:34,  3.77s/it]
 26%|██▌       | 131/505 [08:27<23:29,  3.77s/it]
 26%|██▌       | 132/505 [08:31<23:19,  3.75s/it]
 26%|██▋       | 133/505 [08:35<23:34,  3.80s/it]
 27%|██▋       | 134/505 [08:38<23:32,  3.81s/it]
 27%|██▋       | 135/505 [08:42<23:16,  3.77s/it]
 27%|██▋       | 136/505 [08:46<23:12,  3.77s/it]
 27%|██▋       | 137/505 [08:50<23:02,  3.76s/it]
 27%|██▋       | 138/505 [08:53<23:02,  3.77s/it]
 28%|██▊       | 139/505 [08:57<23:02,  3.78s/it]
 28%|██▊       | 140/505 [09:01<22:51,  3.76s/it]
 28%|██▊       | 141/505 [09:05<22:47,  3.76s/it]
 28%|██▊       | 142/505 [09:08<22:49,  3.77s/it]
 28%|██▊       | 143/505 [09:12<22:47,  3.78s/it]
 29%|██▊       | 144/505 [09:16<22:42,  3.77s/it]
 29%|██▊       | 145/505 [09:20<22:38,  3.77s/it]
 29%|██▉       | 146/505 [09:24<22:34,  3.77s/it]
 29%|██▉       | 147/505 [09:27<22:27,  3.76s/it]
 29%|██▉       | 148/505 [09:31<22:22,  3.76s/it]
 30%|██▉       | 149/505 [09:35<22:18,  3.76s/it]
 30%|██▉       | 150/505 [09:39<22:27,  3.80s/it]
 30%|██▉       | 151/505 [09:42<22:24,  3.80s/it]
 30%|███       | 152/505 [09:46<22:19,  3.79s/it]
 30%|███       | 153/505 [09:50<22:21,  3.81s/it]
 30%|███       | 154/505 [09:54<22:20,  3.82s/it]
 31%|███       | 155/505 [09:58<22:11,  3.80s/it]
 31%|███       | 156/505 [10:01<21:58,  3.78s/it]
 31%|███       | 157/505 [10:05<21:49,  3.76s/it]
 31%|███▏      | 158/505 [10:09<21:55,  3.79s/it]
 31%|███▏      | 159/505 [10:13<21:50,  3.79s/it]
 32%|███▏      | 160/505 [10:17<21:42,  3.77s/it]
 32%|███▏      | 161/505 [10:20<21:41,  3.78s/it]
 32%|███▏      | 162/505 [10:24<21:34,  3.77s/it]
 32%|███▏      | 163/505 [10:28<21:37,  3.79s/it]
 32%|███▏      | 164/505 [10:32<21:32,  3.79s/it]
 33%|███▎      | 165/505 [10:36<21:32,  3.80s/it]
 33%|███▎      | 166/505 [10:39<21:27,  3.80s/it]
 33%|███▎      | 167/505 [10:43<21:24,  3.80s/it]
 33%|███▎      | 168/505 [10:47<21:16,  3.79s/it]
 33%|███▎      | 169/505 [10:51<21:03,  3.76s/it]
 34%|███▎      | 170/505 [10:54<20:57,  3.75s/it]
 34%|███▍      | 171/505 [10:58<21:01,  3.78s/it]
 34%|███▍      | 172/505 [11:02<20:56,  3.77s/it]
 34%|███▍      | 173/505 [11:06<21:00,  3.80s/it]
 34%|███▍      | 174/505 [11:10<20:52,  3.78s/it]
 35%|███▍      | 175/505 [11:13<20:50,  3.79s/it]
 35%|███▍      | 176/505 [11:17<20:43,  3.78s/it]
 35%|███▌      | 177/505 [11:21<20:39,  3.78s/it]
 35%|███▌      | 178/505 [11:25<20:37,  3.78s/it]
 35%|███▌      | 179/505 [11:28<20:30,  3.77s/it]
 36%|███▌      | 180/505 [11:32<20:22,  3.76s/it]
 36%|███▌      | 181/505 [11:36<20:18,  3.76s/it]
 36%|███▌      | 182/505 [11:40<20:16,  3.77s/it]
 36%|███▌      | 183/505 [11:43<20:06,  3.75s/it]
 36%|███▋      | 184/505 [11:47<19:59,  3.74s/it]
 37%|███▋      | 185/505 [11:51<20:01,  3.76s/it]
 37%|███▋      | 186/505 [11:55<20:01,  3.77s/it]
 37%|███▋      | 187/505 [11:58<19:55,  3.76s/it]
 37%|███▋      | 188/505 [12:02<19:48,  3.75s/it]
 37%|███▋      | 189/505 [12:06<19:54,  3.78s/it]
 38%|███▊      | 190/505 [12:10<19:54,  3.79s/it]
 38%|███▊      | 191/505 [12:14<19:46,  3.78s/it]
 38%|███▊      | 192/505 [12:17<19:47,  3.80s/it]
 38%|███▊      | 193/505 [12:21<19:41,  3.79s/it]
 38%|███▊      | 194/505 [12:25<19:41,  3.80s/it]
 39%|███▊      | 195/505 [12:29<19:32,  3.78s/it]
 39%|███▉      | 196/505 [12:33<19:39,  3.82s/it]
 39%|███▉      | 197/505 [12:36<19:28,  3.80s/it]
 39%|███▉      | 198/505 [12:40<19:23,  3.79s/it]
 39%|███▉      | 199/505 [12:44<19:17,  3.78s/it]
 40%|███▉      | 200/505 [12:48<19:06,  3.76s/it]
                                                 
{'loss': 0.2779, 'grad_norm': 0.15171587467193604, 'learning_rate': 7.569586267597808e-05, 'epoch': 1.98}

 40%|███▉      | 200/505 [12:48<19:06,  3.76s/it]
 40%|███▉      | 201/505 [12:51<19:04,  3.77s/it]
 40%|████      | 202/505 [12:55<18:56,  3.75s/it][INFO|trainer.py:4117] 2025-01-06 20:45:56,427 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-06 20:45:56,427 >>   Num examples = 180
[INFO|trainer.py:4122] 2025-01-06 20:45:56,427 >>   Batch size = 1


  0%|          | 0/90 [00:00<?, ?it/s][A

  2%|▏         | 2/90 [00:00<00:07, 12.41it/s][A

  4%|▍         | 4/90 [00:00<00:10,  8.31it/s][A

  6%|▌         | 5/90 [00:00<00:10,  7.90it/s][A

  7%|▋         | 6/90 [00:00<00:11,  7.55it/s][A

  8%|▊         | 7/90 [00:00<00:11,  7.38it/s][A

  9%|▉         | 8/90 [00:01<00:11,  7.28it/s][A

 10%|█         | 9/90 [00:01<00:11,  7.16it/s][A

 11%|█         | 10/90 [00:01<00:11,  7.12it/s][A

 12%|█▏        | 11/90 [00:01<00:11,  6.98it/s][A

 13%|█▎        | 12/90 [00:01<00:11,  6.73it/s][A

 14%|█▍        | 13/90 [00:01<00:11,  6.76it/s][A

 16%|█▌        | 14/90 [00:01<00:11,  6.81it/s][A

 17%|█▋        | 15/90 [00:02<00:11,  6.76it/s][A

 18%|█▊        | 16/90 [00:02<00:10,  6.73it/s][A

 19%|█▉        | 17/90 [00:02<00:10,  6.73it/s][A

 20%|██        | 18/90 [00:02<00:10,  6.79it/s][A

 21%|██        | 19/90 [00:02<00:10,  6.86it/s][A

 22%|██▏       | 20/90 [00:02<00:10,  6.88it/s][A

 23%|██▎       | 21/90 [00:02<00:10,  6.87it/s][A

 24%|██▍       | 22/90 [00:03<00:10,  6.66it/s][A

 26%|██▌       | 23/90 [00:03<00:09,  6.77it/s][A

 27%|██▋       | 24/90 [00:03<00:09,  6.81it/s][A

 28%|██▊       | 25/90 [00:03<00:09,  6.70it/s][A

 29%|██▉       | 26/90 [00:03<00:09,  6.57it/s][A

 30%|███       | 27/90 [00:03<00:09,  6.88it/s][A

 31%|███       | 28/90 [00:03<00:09,  6.63it/s][A

 32%|███▏      | 29/90 [00:04<00:09,  6.55it/s][A

 33%|███▎      | 30/90 [00:04<00:09,  6.65it/s][A

 34%|███▍      | 31/90 [00:04<00:08,  6.73it/s][A

 36%|███▌      | 32/90 [00:04<00:08,  6.59it/s][A

 37%|███▋      | 33/90 [00:04<00:08,  6.71it/s][A

 38%|███▊      | 34/90 [00:04<00:08,  6.74it/s][A

 39%|███▉      | 35/90 [00:05<00:08,  6.79it/s][A

 40%|████      | 36/90 [00:05<00:07,  6.81it/s][A

 41%|████      | 37/90 [00:05<00:07,  6.86it/s][A

 42%|████▏     | 38/90 [00:05<00:07,  6.85it/s][A

 43%|████▎     | 39/90 [00:05<00:07,  6.86it/s][A

 44%|████▍     | 40/90 [00:05<00:07,  6.91it/s][A

 46%|████▌     | 41/90 [00:05<00:07,  6.93it/s][A

 47%|████▋     | 42/90 [00:06<00:06,  6.96it/s][A

 48%|████▊     | 43/90 [00:06<00:06,  7.01it/s][A

 49%|████▉     | 44/90 [00:06<00:06,  7.03it/s][A

 50%|█████     | 45/90 [00:06<00:06,  7.03it/s][A

 51%|█████     | 46/90 [00:06<00:06,  6.99it/s][A

 52%|█████▏    | 47/90 [00:06<00:06,  6.75it/s][A

 53%|█████▎    | 48/90 [00:06<00:06,  6.85it/s][A

 54%|█████▍    | 49/90 [00:07<00:05,  6.91it/s][A

 56%|█████▌    | 50/90 [00:07<00:05,  6.96it/s][A

 57%|█████▋    | 51/90 [00:07<00:05,  6.91it/s][A

 58%|█████▊    | 52/90 [00:07<00:05,  6.89it/s][A

 59%|█████▉    | 53/90 [00:07<00:05,  6.93it/s][A

 60%|██████    | 54/90 [00:07<00:05,  6.96it/s][A

 61%|██████    | 55/90 [00:07<00:05,  6.94it/s][A

 62%|██████▏   | 56/90 [00:08<00:04,  6.91it/s][A

 63%|██████▎   | 57/90 [00:08<00:04,  6.88it/s][A

 64%|██████▍   | 58/90 [00:08<00:04,  6.91it/s][A

 66%|██████▌   | 59/90 [00:08<00:04,  6.55it/s][A

 67%|██████▋   | 60/90 [00:08<00:04,  6.66it/s][A

 68%|██████▊   | 61/90 [00:08<00:04,  6.66it/s][A

 69%|██████▉   | 62/90 [00:08<00:04,  6.84it/s][A

 70%|███████   | 63/90 [00:09<00:03,  6.79it/s][A

 71%|███████   | 64/90 [00:09<00:03,  6.66it/s][A

 72%|███████▏  | 65/90 [00:09<00:03,  6.75it/s][A

 73%|███████▎  | 66/90 [00:09<00:03,  6.78it/s][A

 74%|███████▍  | 67/90 [00:09<00:03,  6.57it/s][A

 76%|███████▌  | 68/90 [00:09<00:03,  6.67it/s][A

 77%|███████▋  | 69/90 [00:10<00:03,  6.76it/s][A

 78%|███████▊  | 70/90 [00:10<00:02,  6.83it/s][A

 79%|███████▉  | 71/90 [00:10<00:02,  6.78it/s][A

 80%|████████  | 72/90 [00:10<00:02,  6.85it/s][A

 81%|████████  | 73/90 [00:10<00:02,  6.64it/s][A

 82%|████████▏ | 74/90 [00:10<00:02,  6.70it/s][A

 83%|████████▎ | 75/90 [00:10<00:02,  6.68it/s][A

 84%|████████▍ | 76/90 [00:11<00:02,  6.56it/s][A

 86%|████████▌ | 77/90 [00:11<00:01,  6.66it/s][A

 87%|████████▋ | 78/90 [00:11<00:01,  6.68it/s][A

 88%|████████▊ | 79/90 [00:11<00:01,  6.73it/s][A

 89%|████████▉ | 80/90 [00:11<00:01,  6.75it/s][A

 90%|█████████ | 81/90 [00:11<00:01,  6.82it/s][A

 91%|█████████ | 82/90 [00:11<00:01,  6.86it/s][A

 92%|█████████▏| 83/90 [00:12<00:01,  6.87it/s][A

 93%|█████████▎| 84/90 [00:12<00:00,  6.87it/s][A

 94%|█████████▍| 85/90 [00:12<00:00,  6.87it/s][A

 96%|█████████▌| 86/90 [00:12<00:00,  6.81it/s][A

 97%|█████████▋| 87/90 [00:12<00:00,  6.63it/s][A

 98%|█████████▊| 88/90 [00:12<00:00,  6.73it/s][A

 99%|█████████▉| 89/90 [00:12<00:00,  6.78it/s][A

100%|██████████| 90/90 [00:13<00:00,  6.82it/s][A
                                                 

                                               
[A{'eval_loss': 0.002244133036583662, 'eval_runtime': 13.2589, 'eval_samples_per_second': 13.576, 'eval_steps_per_second': 6.788, 'epoch': 2.0}

 40%|████      | 202/505 [13:09<18:56,  3.75s/it]

100%|██████████| 90/90 [00:13<00:00,  6.82it/s][A

                                               [A
 40%|████      | 203/505 [13:12<38:57,  7.74s/it]
 40%|████      | 204/505 [13:16<32:43,  6.52s/it]
 41%|████      | 205/505 [13:20<28:29,  5.70s/it]
 41%|████      | 206/505 [13:23<25:28,  5.11s/it]
 41%|████      | 207/505 [13:27<23:26,  4.72s/it]
 41%|████      | 208/505 [13:31<21:54,  4.43s/it]
 41%|████▏     | 209/505 [13:35<20:46,  4.21s/it]
 42%|████▏     | 210/505 [13:38<20:03,  4.08s/it]
 42%|████▏     | 211/505 [13:42<19:48,  4.04s/it]
 42%|████▏     | 212/505 [13:46<19:19,  3.96s/it]
 42%|████▏     | 213/505 [13:50<18:54,  3.88s/it]
 42%|████▏     | 214/505 [13:54<18:33,  3.83s/it]
 43%|████▎     | 215/505 [13:57<18:25,  3.81s/it]
 43%|████▎     | 216/505 [14:01<18:17,  3.80s/it]
 43%|████▎     | 217/505 [14:05<18:12,  3.79s/it]
 43%|████▎     | 218/505 [14:09<18:04,  3.78s/it]
 43%|████▎     | 219/505 [14:12<18:05,  3.79s/it]
 44%|████▎     | 220/505 [14:16<17:53,  3.77s/it]
 44%|████▍     | 221/505 [14:20<17:56,  3.79s/it]
 44%|████▍     | 222/505 [14:24<17:51,  3.79s/it]
 44%|████▍     | 223/505 [14:27<17:41,  3.76s/it]
 44%|████▍     | 224/505 [14:31<17:34,  3.75s/it]
 45%|████▍     | 225/505 [14:35<17:34,  3.77s/it]
 45%|████▍     | 226/505 [14:39<17:32,  3.77s/it]
 45%|████▍     | 227/505 [14:42<17:24,  3.76s/it]
 45%|████▌     | 228/505 [14:46<17:19,  3.75s/it]
 45%|████▌     | 229/505 [14:50<17:27,  3.80s/it]
 46%|████▌     | 230/505 [14:54<17:23,  3.79s/it]
 46%|████▌     | 231/505 [14:58<17:21,  3.80s/it]
 46%|████▌     | 232/505 [15:01<17:13,  3.79s/it]
 46%|████▌     | 233/505 [15:05<17:06,  3.77s/it]
 46%|████▋     | 234/505 [15:09<16:55,  3.75s/it]
 47%|████▋     | 235/505 [15:13<16:54,  3.76s/it]
 47%|████▋     | 236/505 [15:17<16:54,  3.77s/it]
 47%|████▋     | 237/505 [15:20<16:57,  3.80s/it]
 47%|████▋     | 238/505 [15:24<16:51,  3.79s/it]
 47%|████▋     | 239/505 [15:28<16:43,  3.77s/it]
 48%|████▊     | 240/505 [15:32<16:39,  3.77s/it]
 48%|████▊     | 241/505 [15:35<16:29,  3.75s/it]
 48%|████▊     | 242/505 [15:39<16:34,  3.78s/it]
 48%|████▊     | 243/505 [15:43<16:32,  3.79s/it]
 48%|████▊     | 244/505 [15:47<16:31,  3.80s/it]
 49%|████▊     | 245/505 [15:51<16:31,  3.81s/it]
 49%|████▊     | 246/505 [15:54<16:27,  3.81s/it]
 49%|████▉     | 247/505 [15:58<16:19,  3.80s/it]
 49%|████▉     | 248/505 [16:02<16:17,  3.80s/it]
 49%|████▉     | 249/505 [16:06<16:08,  3.78s/it]
 50%|████▉     | 250/505 [16:10<16:00,  3.77s/it]
 50%|████▉     | 251/505 [16:13<15:59,  3.78s/it]
 50%|████▉     | 252/505 [16:17<15:51,  3.76s/it]
 50%|█████     | 253/505 [16:21<15:49,  3.77s/it]
 50%|█████     | 254/505 [16:25<15:53,  3.80s/it]
 50%|█████     | 255/505 [16:28<15:48,  3.79s/it]
 51%|█████     | 256/505 [16:32<15:43,  3.79s/it]
 51%|█████     | 257/505 [16:36<15:39,  3.79s/it]
 51%|█████     | 258/505 [16:40<15:37,  3.79s/it]
 51%|█████▏    | 259/505 [16:44<15:33,  3.80s/it]
 51%|█████▏    | 260/505 [16:48<15:35,  3.82s/it]
 52%|█████▏    | 261/505 [16:51<15:29,  3.81s/it]
 52%|█████▏    | 262/505 [16:55<15:23,  3.80s/it]
 52%|█████▏    | 263/505 [16:59<15:13,  3.77s/it]
 52%|█████▏    | 264/505 [17:03<15:10,  3.78s/it]
 52%|█████▏    | 265/505 [17:06<15:11,  3.80s/it]
 53%|█████▎    | 266/505 [17:10<15:09,  3.81s/it]
 53%|█████▎    | 267/505 [17:14<15:03,  3.80s/it]
 53%|█████▎    | 268/505 [17:18<15:01,  3.81s/it]
 53%|█████▎    | 269/505 [17:22<14:56,  3.80s/it]
 53%|█████▎    | 270/505 [17:26<14:57,  3.82s/it]
 54%|█████▎    | 271/505 [17:29<14:49,  3.80s/it]
 54%|█████▍    | 272/505 [17:33<14:42,  3.79s/it]
 54%|█████▍    | 273/505 [17:37<14:48,  3.83s/it]
 54%|█████▍    | 274/505 [17:41<14:42,  3.82s/it]
 54%|█████▍    | 275/505 [17:45<14:39,  3.82s/it]
 55%|█████▍    | 276/505 [17:48<14:32,  3.81s/it]
 55%|█████▍    | 277/505 [17:52<14:24,  3.79s/it]
 55%|█████▌    | 278/505 [17:56<14:13,  3.76s/it]
 55%|█████▌    | 279/505 [18:00<14:12,  3.77s/it]
 55%|█████▌    | 280/505 [18:03<14:05,  3.76s/it]
 56%|█████▌    | 281/505 [18:07<14:08,  3.79s/it]
 56%|█████▌    | 282/505 [18:11<14:03,  3.78s/it]
 56%|█████▌    | 283/505 [18:15<13:59,  3.78s/it]
 56%|█████▌    | 284/505 [18:19<13:56,  3.79s/it]
 56%|█████▋    | 285/505 [18:22<13:48,  3.76s/it]
 57%|█████▋    | 286/505 [18:26<13:45,  3.77s/it]
 57%|█████▋    | 287/505 [18:30<13:49,  3.81s/it]
 57%|█████▋    | 288/505 [18:34<13:45,  3.80s/it]
 57%|█████▋    | 289/505 [18:38<13:42,  3.81s/it]
 57%|█████▋    | 290/505 [18:41<13:34,  3.79s/it]
 58%|█████▊    | 291/505 [18:45<13:30,  3.79s/it]
 58%|█████▊    | 292/505 [18:49<13:28,  3.80s/it]
 58%|█████▊    | 293/505 [18:53<13:20,  3.78s/it]
 58%|█████▊    | 294/505 [18:56<13:21,  3.80s/it]
 58%|█████▊    | 295/505 [19:00<13:12,  3.77s/it]
 59%|█████▊    | 296/505 [19:04<13:07,  3.77s/it]
 59%|█████▉    | 297/505 [19:08<13:02,  3.76s/it]
 59%|█████▉    | 298/505 [19:12<13:03,  3.78s/it]
 59%|█████▉    | 299/505 [19:15<12:58,  3.78s/it]
 59%|█████▉    | 300/505 [19:19<12:49,  3.75s/it]
 60%|█████▉    | 301/505 [19:23<12:49,  3.77s/it]
 60%|█████▉    | 302/505 [19:27<12:49,  3.79s/it]
 60%|██████    | 303/505 [19:30<12:45,  3.79s/it][INFO|trainer.py:4117] 2025-01-06 20:52:32,132 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-06 20:52:32,132 >>   Num examples = 180
[INFO|trainer.py:4122] 2025-01-06 20:52:32,132 >>   Batch size = 1


  0%|          | 0/90 [00:00<?, ?it/s][A

  2%|▏         | 2/90 [00:00<00:07, 12.47it/s][A

  4%|▍         | 4/90 [00:00<00:10,  8.37it/s][A

  6%|▌         | 5/90 [00:00<00:10,  7.92it/s][A

  7%|▋         | 6/90 [00:00<00:11,  7.53it/s][A

  8%|▊         | 7/90 [00:00<00:11,  7.31it/s][A

  9%|▉         | 8/90 [00:01<00:11,  7.17it/s][A

 10%|█         | 9/90 [00:01<00:11,  7.07it/s][A

 11%|█         | 10/90 [00:01<00:11,  7.01it/s][A

 12%|█▏        | 11/90 [00:01<00:11,  6.90it/s][A

 13%|█▎        | 12/90 [00:01<00:11,  6.67it/s][A

 14%|█▍        | 13/90 [00:01<00:11,  6.74it/s][A

 16%|█▌        | 14/90 [00:01<00:11,  6.82it/s][A

 17%|█▋        | 15/90 [00:02<00:11,  6.76it/s][A

 18%|█▊        | 16/90 [00:02<00:10,  6.83it/s][A

 19%|█▉        | 17/90 [00:02<00:10,  6.82it/s][A

 20%|██        | 18/90 [00:02<00:10,  6.79it/s][A

 21%|██        | 19/90 [00:02<00:10,  6.84it/s][A

 22%|██▏       | 20/90 [00:02<00:10,  6.88it/s][A

 23%|██▎       | 21/90 [00:02<00:10,  6.89it/s][A

 24%|██▍       | 22/90 [00:03<00:10,  6.69it/s][A

 26%|██▌       | 23/90 [00:03<00:09,  6.79it/s][A

 27%|██▋       | 24/90 [00:03<00:09,  6.80it/s][A

 28%|██▊       | 25/90 [00:03<00:09,  6.65it/s][A

 29%|██▉       | 26/90 [00:03<00:09,  6.54it/s][A

 30%|███       | 27/90 [00:03<00:09,  6.84it/s][A

 31%|███       | 28/90 [00:04<00:09,  6.71it/s][A

 32%|███▏      | 29/90 [00:04<00:09,  6.56it/s][A

 33%|███▎      | 30/90 [00:04<00:09,  6.66it/s][A

 34%|███▍      | 31/90 [00:04<00:08,  6.75it/s][A

 36%|███▌      | 32/90 [00:04<00:08,  6.61it/s][A

 37%|███▋      | 33/90 [00:04<00:08,  6.75it/s][A

 38%|███▊      | 34/90 [00:04<00:08,  6.78it/s][A

 39%|███▉      | 35/90 [00:05<00:08,  6.81it/s][A

 40%|████      | 36/90 [00:05<00:07,  6.83it/s][A

 41%|████      | 37/90 [00:05<00:07,  6.88it/s][A

 42%|████▏     | 38/90 [00:05<00:07,  6.91it/s][A

 43%|████▎     | 39/90 [00:05<00:07,  6.95it/s][A

 44%|████▍     | 40/90 [00:05<00:07,  6.98it/s][A

 46%|████▌     | 41/90 [00:05<00:07,  6.95it/s][A

 47%|████▋     | 42/90 [00:06<00:06,  6.92it/s][A

 48%|████▊     | 43/90 [00:06<00:06,  6.91it/s][A

 49%|████▉     | 44/90 [00:06<00:06,  6.92it/s][A

 50%|█████     | 45/90 [00:06<00:06,  6.92it/s][A

 51%|█████     | 46/90 [00:06<00:06,  6.90it/s][A

 52%|█████▏    | 47/90 [00:06<00:06,  6.70it/s][A

 53%|█████▎    | 48/90 [00:06<00:06,  6.80it/s][A

 54%|█████▍    | 49/90 [00:07<00:05,  6.84it/s][A

 56%|█████▌    | 50/90 [00:07<00:05,  6.87it/s][A

 57%|█████▋    | 51/90 [00:07<00:05,  6.85it/s][A

 58%|█████▊    | 52/90 [00:07<00:05,  6.87it/s][A

 59%|█████▉    | 53/90 [00:07<00:05,  6.94it/s][A

 60%|██████    | 54/90 [00:07<00:05,  7.01it/s][A

 61%|██████    | 55/90 [00:07<00:05,  7.00it/s][A

 62%|██████▏   | 56/90 [00:08<00:04,  6.98it/s][A

 63%|██████▎   | 57/90 [00:08<00:04,  6.95it/s][A

 64%|██████▍   | 58/90 [00:08<00:04,  6.96it/s][A

 66%|██████▌   | 59/90 [00:08<00:04,  6.56it/s][A

 67%|██████▋   | 60/90 [00:08<00:04,  6.65it/s][A

 68%|██████▊   | 61/90 [00:08<00:04,  6.65it/s][A

 69%|██████▉   | 62/90 [00:08<00:04,  6.80it/s][A

 70%|███████   | 63/90 [00:09<00:03,  6.76it/s][A

 71%|███████   | 64/90 [00:09<00:03,  6.63it/s][A

 72%|███████▏  | 65/90 [00:09<00:03,  6.73it/s][A

 73%|███████▎  | 66/90 [00:09<00:03,  6.76it/s][A

 74%|███████▍  | 67/90 [00:09<00:03,  6.56it/s][A

 76%|███████▌  | 68/90 [00:09<00:03,  6.67it/s][A

 77%|███████▋  | 69/90 [00:10<00:03,  6.75it/s][A

 78%|███████▊  | 70/90 [00:10<00:02,  6.81it/s][A

 79%|███████▉  | 71/90 [00:10<00:02,  6.77it/s][A

 80%|████████  | 72/90 [00:10<00:02,  6.84it/s][A

 81%|████████  | 73/90 [00:10<00:02,  6.65it/s][A

 82%|████████▏ | 74/90 [00:10<00:02,  6.73it/s][A

 83%|████████▎ | 75/90 [00:10<00:02,  6.71it/s][A

 84%|████████▍ | 76/90 [00:11<00:02,  6.58it/s][A

 86%|████████▌ | 77/90 [00:11<00:01,  6.72it/s][A

 87%|████████▋ | 78/90 [00:11<00:01,  6.71it/s][A

 88%|████████▊ | 79/90 [00:11<00:01,  6.79it/s][A

 89%|████████▉ | 80/90 [00:11<00:01,  6.80it/s][A

 90%|█████████ | 81/90 [00:11<00:01,  6.83it/s][A

 91%|█████████ | 82/90 [00:11<00:01,  6.83it/s][A

 92%|█████████▏| 83/90 [00:12<00:01,  6.84it/s][A

 93%|█████████▎| 84/90 [00:12<00:00,  6.86it/s][A

 94%|█████████▍| 85/90 [00:12<00:00,  6.87it/s][A

 96%|█████████▌| 86/90 [00:12<00:00,  6.81it/s][A

 97%|█████████▋| 87/90 [00:12<00:00,  6.63it/s][A

 98%|█████████▊| 88/90 [00:12<00:00,  6.73it/s][A

 99%|█████████▉| 89/90 [00:12<00:00,  6.77it/s][A

100%|██████████| 90/90 [00:13<00:00,  6.80it/s][A
                                                 

                                               
[A{'eval_loss': 0.0025029820390045643, 'eval_runtime': 13.266, 'eval_samples_per_second': 13.569, 'eval_steps_per_second': 6.784, 'epoch': 3.0}

 60%|██████    | 303/505 [19:45<12:45,  3.79s/it]

100%|██████████| 90/90 [00:13<00:00,  6.80it/s][A

                                               [A
 60%|██████    | 304/505 [19:47<25:58,  7.75s/it]
 60%|██████    | 305/505 [19:51<21:50,  6.55s/it]
 61%|██████    | 306/505 [19:55<18:58,  5.72s/it]
 61%|██████    | 307/505 [19:59<16:54,  5.13s/it]
 61%|██████    | 308/505 [20:02<15:31,  4.73s/it]
 61%|██████    | 309/505 [20:06<14:32,  4.45s/it]
 61%|██████▏   | 310/505 [20:10<13:50,  4.26s/it]
 62%|██████▏   | 311/505 [20:14<13:22,  4.13s/it]
 62%|██████▏   | 312/505 [20:18<12:57,  4.03s/it]
 62%|██████▏   | 313/505 [20:22<12:39,  3.96s/it]
 62%|██████▏   | 314/505 [20:25<12:27,  3.91s/it]
 62%|██████▏   | 315/505 [20:29<12:16,  3.88s/it]
 63%|██████▎   | 316/505 [20:33<12:02,  3.83s/it]
 63%|██████▎   | 317/505 [20:37<12:01,  3.84s/it]
 63%|██████▎   | 318/505 [20:40<11:54,  3.82s/it]
 63%|██████▎   | 319/505 [20:44<11:44,  3.79s/it]
 63%|██████▎   | 320/505 [20:48<11:41,  3.79s/it]
 64%|██████▎   | 321/505 [20:52<11:39,  3.80s/it]
 64%|██████▍   | 322/505 [20:56<11:39,  3.82s/it]
 64%|██████▍   | 323/505 [20:59<11:34,  3.82s/it]
 64%|██████▍   | 324/505 [21:03<11:30,  3.81s/it]
 64%|██████▍   | 325/505 [21:07<11:29,  3.83s/it]
 65%|██████▍   | 326/505 [21:11<11:20,  3.80s/it]
 65%|██████▍   | 327/505 [21:15<11:14,  3.79s/it]
 65%|██████▍   | 328/505 [21:18<11:11,  3.79s/it]
 65%|██████▌   | 329/505 [21:22<11:06,  3.79s/it]
 65%|██████▌   | 330/505 [21:26<11:02,  3.78s/it]
 66%|██████▌   | 331/505 [21:30<10:56,  3.77s/it]
 66%|██████▌   | 332/505 [21:34<10:53,  3.78s/it]
 66%|██████▌   | 333/505 [21:37<10:54,  3.80s/it]
 66%|██████▌   | 334/505 [21:41<10:49,  3.80s/it]
 66%|██████▋   | 335/505 [21:45<10:47,  3.81s/it]
 67%|██████▋   | 336/505 [21:49<10:40,  3.79s/it]
 67%|██████▋   | 337/505 [21:53<10:42,  3.82s/it]
 67%|██████▋   | 338/505 [21:57<10:40,  3.83s/it]
 67%|██████▋   | 339/505 [22:00<10:36,  3.83s/it]
 67%|██████▋   | 340/505 [22:04<10:32,  3.83s/it]
 68%|██████▊   | 341/505 [22:08<10:23,  3.80s/it]
 68%|██████▊   | 342/505 [22:12<10:20,  3.81s/it]
 68%|██████▊   | 343/505 [22:15<10:13,  3.79s/it]
 68%|██████▊   | 344/505 [22:19<10:11,  3.80s/it]
 68%|██████▊   | 345/505 [22:23<10:05,  3.78s/it]
 69%|██████▊   | 346/505 [22:27<10:04,  3.80s/it]
 69%|██████▊   | 347/505 [22:31<09:58,  3.79s/it]
 69%|██████▉   | 348/505 [22:34<09:52,  3.78s/it]
 69%|██████▉   | 349/505 [22:38<09:51,  3.79s/it]
 69%|██████▉   | 350/505 [22:42<09:54,  3.83s/it]
 70%|██████▉   | 351/505 [22:46<09:50,  3.84s/it]
 70%|██████▉   | 352/505 [22:50<09:43,  3.82s/it]
 70%|██████▉   | 353/505 [22:54<09:39,  3.82s/it]
 70%|███████   | 354/505 [22:57<09:35,  3.81s/it]
 70%|███████   | 355/505 [23:01<09:28,  3.79s/it]
 70%|███████   | 356/505 [23:05<09:23,  3.78s/it]
 71%|███████   | 357/505 [23:09<09:18,  3.78s/it]
 71%|███████   | 358/505 [23:12<09:16,  3.79s/it]
 71%|███████   | 359/505 [23:16<09:11,  3.78s/it]
 71%|███████▏  | 360/505 [23:20<09:07,  3.78s/it]
 71%|███████▏  | 361/505 [23:24<09:04,  3.78s/it]
 72%|███████▏  | 362/505 [23:27<08:56,  3.75s/it]
 72%|███████▏  | 363/505 [23:31<08:51,  3.75s/it]
 72%|███████▏  | 364/505 [23:35<08:48,  3.75s/it]
 72%|███████▏  | 365/505 [23:39<08:44,  3.75s/it]
 72%|███████▏  | 366/505 [23:43<08:45,  3.78s/it]
 73%|███████▎  | 367/505 [23:46<08:44,  3.80s/it]
 73%|███████▎  | 368/505 [23:50<08:39,  3.79s/it]
 73%|███████▎  | 369/505 [23:54<08:34,  3.78s/it]
 73%|███████▎  | 370/505 [23:58<08:27,  3.76s/it]
 73%|███████▎  | 371/505 [24:01<08:26,  3.78s/it]
 74%|███████▎  | 372/505 [24:05<08:20,  3.76s/it]
 74%|███████▍  | 373/505 [24:09<08:15,  3.75s/it]
 74%|███████▍  | 374/505 [24:13<08:08,  3.73s/it]
 74%|███████▍  | 375/505 [24:16<08:05,  3.73s/it]
 74%|███████▍  | 376/505 [24:20<08:07,  3.78s/it]
 75%|███████▍  | 377/505 [24:24<08:00,  3.76s/it]
 75%|███████▍  | 378/505 [24:28<07:56,  3.75s/it]
 75%|███████▌  | 379/505 [24:31<07:54,  3.76s/it]
 75%|███████▌  | 380/505 [24:35<07:50,  3.76s/it]
 75%|███████▌  | 381/505 [24:39<07:48,  3.78s/it]
 76%|███████▌  | 382/505 [24:43<07:44,  3.78s/it]
 76%|███████▌  | 383/505 [24:47<07:42,  3.79s/it]
 76%|███████▌  | 384/505 [24:50<07:38,  3.79s/it]
 76%|███████▌  | 385/505 [24:54<07:34,  3.78s/it]
 76%|███████▋  | 386/505 [24:58<07:29,  3.78s/it]
 77%|███████▋  | 387/505 [25:02<07:27,  3.80s/it]
 77%|███████▋  | 388/505 [25:06<07:25,  3.81s/it]
 77%|███████▋  | 389/505 [25:09<07:21,  3.80s/it]
 77%|███████▋  | 390/505 [25:13<07:15,  3.79s/it]
 77%|███████▋  | 391/505 [25:17<07:12,  3.79s/it]
 78%|███████▊  | 392/505 [25:21<07:05,  3.77s/it]
 78%|███████▊  | 393/505 [25:24<07:00,  3.76s/it]
 78%|███████▊  | 394/505 [25:28<06:57,  3.76s/it]
 78%|███████▊  | 395/505 [25:32<06:58,  3.80s/it]
 78%|███████▊  | 396/505 [25:36<06:51,  3.78s/it]
 79%|███████▊  | 397/505 [25:40<06:47,  3.78s/it]
 79%|███████▉  | 398/505 [25:43<06:44,  3.78s/it]
 79%|███████▉  | 399/505 [25:47<06:38,  3.76s/it]
 79%|███████▉  | 400/505 [25:51<06:34,  3.76s/it]
                                                 
{'loss': 0.0006, 'grad_norm': 0.009521812200546265, 'learning_rate': 1.2627456608605443e-05, 'epoch': 3.96}

 79%|███████▉  | 400/505 [25:51<06:34,  3.76s/it]
 79%|███████▉  | 401/505 [25:55<06:30,  3.76s/it]
 80%|███████▉  | 402/505 [25:58<06:27,  3.76s/it]
 80%|███████▉  | 403/505 [26:02<06:23,  3.76s/it]
 80%|████████  | 404/505 [26:06<06:19,  3.76s/it][INFO|trainer.py:4117] 2025-01-06 20:59:08,124 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-06 20:59:08,124 >>   Num examples = 180
[INFO|trainer.py:4122] 2025-01-06 20:59:08,124 >>   Batch size = 1


  0%|          | 0/90 [00:00<?, ?it/s][A

  2%|▏         | 2/90 [00:00<00:07, 12.31it/s][A

  4%|▍         | 4/90 [00:00<00:10,  8.35it/s][A

  6%|▌         | 5/90 [00:00<00:10,  7.94it/s][A

  7%|▋         | 6/90 [00:00<00:11,  7.61it/s][A

  8%|▊         | 7/90 [00:00<00:11,  7.40it/s][A

  9%|▉         | 8/90 [00:01<00:11,  7.26it/s][A

 10%|█         | 9/90 [00:01<00:11,  7.14it/s][A

 11%|█         | 10/90 [00:01<00:11,  7.08it/s][A

 12%|█▏        | 11/90 [00:01<00:11,  6.95it/s][A

 13%|█▎        | 12/90 [00:01<00:11,  6.74it/s][A

 14%|█▍        | 13/90 [00:01<00:11,  6.80it/s][A

 16%|█▌        | 14/90 [00:01<00:11,  6.86it/s][A

 17%|█▋        | 15/90 [00:02<00:11,  6.79it/s][A

 18%|█▊        | 16/90 [00:02<00:10,  6.83it/s][A

 19%|█▉        | 17/90 [00:02<00:10,  6.86it/s][A

 20%|██        | 18/90 [00:02<00:10,  6.87it/s][A

 21%|██        | 19/90 [00:02<00:10,  6.89it/s][A

 22%|██▏       | 20/90 [00:02<00:10,  6.89it/s][A

 23%|██▎       | 21/90 [00:02<00:10,  6.88it/s][A

 24%|██▍       | 22/90 [00:03<00:10,  6.66it/s][A

 26%|██▌       | 23/90 [00:03<00:09,  6.76it/s][A

 27%|██▋       | 24/90 [00:03<00:09,  6.81it/s][A

 28%|██▊       | 25/90 [00:03<00:09,  6.70it/s][A

 29%|██▉       | 26/90 [00:03<00:09,  6.57it/s][A

 30%|███       | 27/90 [00:03<00:09,  6.84it/s][A

 31%|███       | 28/90 [00:03<00:09,  6.69it/s][A

 32%|███▏      | 29/90 [00:04<00:09,  6.54it/s][A

 33%|███▎      | 30/90 [00:04<00:09,  6.62it/s][A

 34%|███▍      | 31/90 [00:04<00:08,  6.70it/s][A

 36%|███▌      | 32/90 [00:04<00:08,  6.57it/s][A

 37%|███▋      | 33/90 [00:04<00:08,  6.72it/s][A

 38%|███▊      | 34/90 [00:04<00:08,  6.78it/s][A

 39%|███▉      | 35/90 [00:05<00:08,  6.86it/s][A

 40%|████      | 36/90 [00:05<00:07,  6.88it/s][A

 41%|████      | 37/90 [00:05<00:07,  6.92it/s][A

 42%|████▏     | 38/90 [00:05<00:07,  6.89it/s][A

 43%|████▎     | 39/90 [00:05<00:07,  6.90it/s][A

 44%|████▍     | 40/90 [00:05<00:07,  6.92it/s][A

 46%|████▌     | 41/90 [00:05<00:07,  6.90it/s][A

 47%|████▋     | 42/90 [00:06<00:06,  6.92it/s][A

 48%|████▊     | 43/90 [00:06<00:06,  6.96it/s][A

 49%|████▉     | 44/90 [00:06<00:06,  7.00it/s][A

 50%|█████     | 45/90 [00:06<00:06,  7.01it/s][A

 51%|█████     | 46/90 [00:06<00:06,  6.98it/s][A

 52%|█████▏    | 47/90 [00:06<00:06,  6.74it/s][A

 53%|█████▎    | 48/90 [00:06<00:06,  6.80it/s][A

 54%|█████▍    | 49/90 [00:07<00:05,  6.84it/s][A

 56%|█████▌    | 50/90 [00:07<00:05,  6.88it/s][A

 57%|█████▋    | 51/90 [00:07<00:05,  6.86it/s][A

 58%|█████▊    | 52/90 [00:07<00:05,  6.87it/s][A

 59%|█████▉    | 53/90 [00:07<00:05,  6.91it/s][A

 60%|██████    | 54/90 [00:07<00:05,  6.94it/s][A

 61%|██████    | 55/90 [00:07<00:05,  6.93it/s][A

 62%|██████▏   | 56/90 [00:08<00:04,  6.92it/s][A

 63%|██████▎   | 57/90 [00:08<00:04,  6.89it/s][A

 64%|██████▍   | 58/90 [00:08<00:04,  6.90it/s][A

 66%|██████▌   | 59/90 [00:08<00:04,  6.52it/s][A

 67%|██████▋   | 60/90 [00:08<00:04,  6.61it/s][A

 68%|██████▊   | 61/90 [00:08<00:04,  6.62it/s][A

 69%|██████▉   | 62/90 [00:08<00:04,  6.75it/s][A

 70%|███████   | 63/90 [00:09<00:04,  6.72it/s][A

 71%|███████   | 64/90 [00:09<00:03,  6.59it/s][A

 72%|███████▏  | 65/90 [00:09<00:03,  6.68it/s][A

 73%|███████▎  | 66/90 [00:09<00:03,  6.74it/s][A

 74%|███████▍  | 67/90 [00:09<00:03,  6.54it/s][A

 76%|███████▌  | 68/90 [00:09<00:03,  6.66it/s][A

 77%|███████▋  | 69/90 [00:10<00:03,  6.76it/s][A

 78%|███████▊  | 70/90 [00:10<00:02,  6.83it/s][A

 79%|███████▉  | 71/90 [00:10<00:02,  6.78it/s][A

 80%|████████  | 72/90 [00:10<00:02,  6.84it/s][A

 81%|████████  | 73/90 [00:10<00:02,  6.64it/s][A

 82%|████████▏ | 74/90 [00:10<00:02,  6.73it/s][A

 83%|████████▎ | 75/90 [00:10<00:02,  6.67it/s][A

 84%|████████▍ | 76/90 [00:11<00:02,  6.54it/s][A

 86%|████████▌ | 77/90 [00:11<00:01,  6.65it/s][A

 87%|████████▋ | 78/90 [00:11<00:01,  6.66it/s][A

 88%|████████▊ | 79/90 [00:11<00:01,  6.74it/s][A

 89%|████████▉ | 80/90 [00:11<00:01,  6.76it/s][A

 90%|█████████ | 81/90 [00:11<00:01,  6.81it/s][A

 91%|█████████ | 82/90 [00:11<00:01,  6.82it/s][A

 92%|█████████▏| 83/90 [00:12<00:01,  6.82it/s][A

 93%|█████████▎| 84/90 [00:12<00:00,  6.81it/s][A

 94%|█████████▍| 85/90 [00:12<00:00,  6.82it/s][A

 96%|█████████▌| 86/90 [00:12<00:00,  6.77it/s][A

 97%|█████████▋| 87/90 [00:12<00:00,  6.63it/s][A

 98%|█████████▊| 88/90 [00:12<00:00,  6.75it/s][A

 99%|█████████▉| 89/90 [00:12<00:00,  6.82it/s][A

100%|██████████| 90/90 [00:13<00:00,  6.89it/s][A
                                                 

                                               
[A{'eval_loss': 0.0026895233895629644, 'eval_runtime': 13.2679, 'eval_samples_per_second': 13.567, 'eval_steps_per_second': 6.783, 'epoch': 4.0}

 80%|████████  | 404/505 [26:21<06:19,  3.76s/it]

100%|██████████| 90/90 [00:13<00:00,  6.89it/s][A

                                               [A
 80%|████████  | 405/505 [26:23<12:56,  7.76s/it]
 80%|████████  | 406/505 [26:27<10:49,  6.56s/it]
 81%|████████  | 407/505 [26:31<09:21,  5.72s/it]
 81%|████████  | 408/505 [26:34<08:19,  5.15s/it]
 81%|████████  | 409/505 [26:38<07:35,  4.74s/it]
 81%|████████  | 410/505 [26:42<07:04,  4.47s/it]
 81%|████████▏ | 411/505 [26:46<06:40,  4.26s/it]
 82%|████████▏ | 412/505 [26:50<06:22,  4.11s/it]
 82%|████████▏ | 413/505 [26:53<06:08,  4.00s/it]
 82%|████████▏ | 414/505 [26:57<05:55,  3.91s/it]
 82%|████████▏ | 415/505 [27:01<05:48,  3.87s/it]
 82%|████████▏ | 416/505 [27:04<05:41,  3.84s/it]
 83%|████████▎ | 417/505 [27:08<05:36,  3.83s/it]
 83%|████████▎ | 418/505 [27:12<05:31,  3.81s/it]
 83%|████████▎ | 419/505 [27:16<05:29,  3.83s/it]
 83%|████████▎ | 420/505 [27:20<05:23,  3.81s/it]
 83%|████████▎ | 421/505 [27:23<05:19,  3.80s/it]
 84%|████████▎ | 422/505 [27:27<05:15,  3.80s/it]
 84%|████████▍ | 423/505 [27:31<05:11,  3.80s/it]
 84%|████████▍ | 424/505 [27:35<05:06,  3.78s/it]
 84%|████████▍ | 425/505 [27:39<05:05,  3.81s/it]
 84%|████████▍ | 426/505 [27:42<05:00,  3.80s/it]
 85%|████████▍ | 427/505 [27:46<04:57,  3.81s/it]
 85%|████████▍ | 428/505 [27:50<04:50,  3.77s/it]
 85%|████████▍ | 429/505 [27:54<04:46,  3.77s/it]
 85%|████████▌ | 430/505 [27:58<04:41,  3.76s/it]
 85%|████████▌ | 431/505 [28:01<04:37,  3.75s/it]
 86%|████████▌ | 432/505 [28:05<04:33,  3.75s/it]
 86%|████████▌ | 433/505 [28:09<04:31,  3.78s/it]
 86%|████████▌ | 434/505 [28:13<04:26,  3.76s/it]
 86%|████████▌ | 435/505 [28:16<04:23,  3.76s/it]
 86%|████████▋ | 436/505 [28:20<04:19,  3.76s/it]
 87%|████████▋ | 437/505 [28:24<04:16,  3.77s/it]
 87%|████████▋ | 438/505 [28:28<04:11,  3.76s/it]
 87%|████████▋ | 439/505 [28:31<04:08,  3.77s/it]
 87%|████████▋ | 440/505 [28:35<04:04,  3.77s/it]
 87%|████████▋ | 441/505 [28:39<04:00,  3.76s/it]
 88%|████████▊ | 442/505 [28:43<03:57,  3.78s/it]
 88%|████████▊ | 443/505 [28:47<03:55,  3.80s/it]
 88%|████████▊ | 444/505 [28:50<03:49,  3.77s/it]
 88%|████████▊ | 445/505 [28:54<03:46,  3.78s/it]
 88%|████████▊ | 446/505 [28:58<03:44,  3.80s/it]
 89%|████████▊ | 447/505 [29:02<03:39,  3.79s/it]
 89%|████████▊ | 448/505 [29:05<03:35,  3.78s/it]
 89%|████████▉ | 449/505 [29:09<03:32,  3.79s/it]
 89%|████████▉ | 450/505 [29:13<03:27,  3.77s/it]
 89%|████████▉ | 451/505 [29:17<03:24,  3.79s/it]
 90%|████████▉ | 452/505 [29:21<03:20,  3.78s/it]
 90%|████████▉ | 453/505 [29:24<03:17,  3.79s/it]
 90%|████████▉ | 454/505 [29:28<03:13,  3.79s/it]
 90%|█████████ | 455/505 [29:32<03:09,  3.79s/it]
 90%|█████████ | 456/505 [29:36<03:06,  3.80s/it]
 90%|█████████ | 457/505 [29:39<03:00,  3.77s/it]
 91%|█████████ | 458/505 [29:43<02:58,  3.79s/it]
 91%|█████████ | 459/505 [29:47<02:53,  3.78s/it]
 91%|█████████ | 460/505 [29:51<02:50,  3.78s/it]
 91%|█████████▏| 461/505 [29:55<02:47,  3.81s/it]
 91%|█████████▏| 462/505 [29:59<02:43,  3.81s/it]
 92%|█████████▏| 463/505 [30:02<02:40,  3.83s/it]
 92%|█████████▏| 464/505 [30:06<02:35,  3.80s/it]
 92%|█████████▏| 465/505 [30:10<02:31,  3.79s/it]
 92%|█████████▏| 466/505 [30:14<02:27,  3.78s/it]
 92%|█████████▏| 467/505 [30:17<02:23,  3.77s/it]
 93%|█████████▎| 468/505 [30:21<02:19,  3.78s/it]
 93%|█████████▎| 469/505 [30:25<02:16,  3.80s/it]
 93%|█████████▎| 470/505 [30:29<02:12,  3.78s/it]
 93%|█████████▎| 471/505 [30:33<02:08,  3.77s/it]
 93%|█████████▎| 472/505 [30:36<02:04,  3.78s/it]
 94%|█████████▎| 473/505 [30:40<02:00,  3.77s/it]
 94%|█████████▍| 474/505 [30:44<01:56,  3.75s/it]
 94%|█████████▍| 475/505 [30:47<01:52,  3.74s/it]
 94%|█████████▍| 476/505 [30:51<01:49,  3.77s/it]
 94%|█████████▍| 477/505 [30:55<01:46,  3.80s/it]
 95%|█████████▍| 478/505 [30:59<01:42,  3.78s/it]
 95%|█████████▍| 479/505 [31:03<01:38,  3.81s/it]
 95%|█████████▌| 480/505 [31:07<01:35,  3.82s/it]
 95%|█████████▌| 481/505 [31:10<01:31,  3.81s/it]
 95%|█████████▌| 482/505 [31:14<01:27,  3.80s/it]
 96%|█████████▌| 483/505 [31:18<01:23,  3.79s/it]
 96%|█████████▌| 484/505 [31:22<01:19,  3.80s/it]
 96%|█████████▌| 485/505 [31:26<01:16,  3.83s/it]
 96%|█████████▌| 486/505 [31:30<01:13,  3.85s/it]
 96%|█████████▋| 487/505 [31:33<01:08,  3.82s/it]
 97%|█████████▋| 488/505 [31:37<01:05,  3.83s/it]
 97%|█████████▋| 489/505 [31:41<01:01,  3.83s/it]
 97%|█████████▋| 490/505 [31:45<00:57,  3.82s/it]
 97%|█████████▋| 491/505 [31:49<00:53,  3.82s/it]
 97%|█████████▋| 492/505 [31:53<00:49,  3.84s/it]
 98%|█████████▊| 493/505 [31:56<00:45,  3.83s/it]
 98%|█████████▊| 494/505 [32:00<00:41,  3.80s/it]
 98%|█████████▊| 495/505 [32:04<00:37,  3.78s/it]
 98%|█████████▊| 496/505 [32:08<00:33,  3.76s/it]
 98%|█████████▊| 497/505 [32:11<00:30,  3.78s/it]
 99%|█████████▊| 498/505 [32:15<00:26,  3.76s/it]
 99%|█████████▉| 499/505 [32:19<00:22,  3.78s/it]
 99%|█████████▉| 500/505 [32:23<00:18,  3.78s/it]
 99%|█████████▉| 501/505 [32:26<00:15,  3.77s/it]
 99%|█████████▉| 502/505 [32:30<00:11,  3.77s/it]
100%|█████████▉| 503/505 [32:34<00:07,  3.77s/it]
100%|█████████▉| 504/505 [32:38<00:03,  3.76s/it]
100%|██████████| 505/505 [32:41<00:00,  3.78s/it][INFO|trainer.py:3801] 2025-01-06 21:05:41,898 >> Saving model checkpoint to saves/qwen-14b-nl-e5/lora/sft/checkpoint-505
[INFO|configuration_utils.py:677] 2025-01-06 21:05:41,918 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-06 21:05:41,918 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2646] 2025-01-06 21:05:42,046 >> tokenizer config file saved in saves/qwen-14b-nl-e5/lora/sft/checkpoint-505/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2025-01-06 21:05:42,046 >> Special tokens file saved in saves/qwen-14b-nl-e5/lora/sft/checkpoint-505/special_tokens_map.json
[INFO|trainer.py:4117] 2025-01-06 21:05:42,295 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-06 21:05:42,295 >>   Num examples = 180
[INFO|trainer.py:4122] 2025-01-06 21:05:42,295 >>   Batch size = 1


  0%|          | 0/90 [00:00<?, ?it/s][A

  2%|▏         | 2/90 [00:00<00:06, 13.21it/s][A

  4%|▍         | 4/90 [00:00<00:09,  8.65it/s][A

  6%|▌         | 5/90 [00:00<00:10,  8.19it/s][A

  7%|▋         | 6/90 [00:00<00:10,  7.80it/s][A

  8%|▊         | 7/90 [00:00<00:10,  7.58it/s][A

  9%|▉         | 8/90 [00:01<00:11,  7.42it/s][A

 10%|█         | 9/90 [00:01<00:11,  7.25it/s][A

 11%|█         | 10/90 [00:01<00:11,  7.17it/s][A

 12%|█▏        | 11/90 [00:01<00:11,  7.01it/s][A

 13%|█▎        | 12/90 [00:01<00:11,  6.76it/s][A

 14%|█▍        | 13/90 [00:01<00:11,  6.81it/s][A

 16%|█▌        | 14/90 [00:01<00:11,  6.89it/s][A

 17%|█▋        | 15/90 [00:02<00:11,  6.81it/s][A

 18%|█▊        | 16/90 [00:02<00:10,  6.88it/s][A

 19%|█▉        | 17/90 [00:02<00:10,  6.85it/s][A

 20%|██        | 18/90 [00:02<00:10,  6.82it/s][A

 21%|██        | 19/90 [00:02<00:10,  6.87it/s][A

 22%|██▏       | 20/90 [00:02<00:10,  6.90it/s][A

 23%|██▎       | 21/90 [00:02<00:09,  6.91it/s][A

 24%|██▍       | 22/90 [00:03<00:10,  6.71it/s][A

 26%|██▌       | 23/90 [00:03<00:09,  6.80it/s][A

 27%|██▋       | 24/90 [00:03<00:09,  6.82it/s][A

 28%|██▊       | 25/90 [00:03<00:09,  6.68it/s][A

 29%|██▉       | 26/90 [00:03<00:09,  6.56it/s][A

 30%|███       | 27/90 [00:03<00:09,  6.86it/s][A

 31%|███       | 28/90 [00:03<00:09,  6.72it/s][A

 32%|███▏      | 29/90 [00:04<00:09,  6.57it/s][A

 33%|███▎      | 30/90 [00:04<00:08,  6.67it/s][A

 34%|███▍      | 31/90 [00:04<00:08,  6.76it/s][A

 36%|███▌      | 32/90 [00:04<00:08,  6.61it/s][A

 37%|███▋      | 33/90 [00:04<00:08,  6.76it/s][A

 38%|███▊      | 34/90 [00:04<00:08,  6.81it/s][A

 39%|███▉      | 35/90 [00:04<00:08,  6.85it/s][A

 40%|████      | 36/90 [00:05<00:07,  6.87it/s][A

 41%|████      | 37/90 [00:05<00:07,  6.90it/s][A

 42%|████▏     | 38/90 [00:05<00:07,  6.90it/s][A

 43%|████▎     | 39/90 [00:05<00:07,  6.92it/s][A

 44%|████▍     | 40/90 [00:05<00:07,  6.97it/s][A

 46%|████▌     | 41/90 [00:05<00:07,  6.96it/s][A

 47%|████▋     | 42/90 [00:05<00:06,  6.96it/s][A

 48%|████▊     | 43/90 [00:06<00:06,  6.96it/s][A

 49%|████▉     | 44/90 [00:06<00:06,  6.97it/s][A

 50%|█████     | 45/90 [00:06<00:06,  6.95it/s][A

 51%|█████     | 46/90 [00:06<00:06,  6.90it/s][A

 52%|█████▏    | 47/90 [00:06<00:06,  6.68it/s][A

 53%|█████▎    | 48/90 [00:06<00:06,  6.78it/s][A

 54%|█████▍    | 49/90 [00:07<00:05,  6.84it/s][A

 56%|█████▌    | 50/90 [00:07<00:05,  6.90it/s][A

 57%|█████▋    | 51/90 [00:07<00:05,  6.88it/s][A

 58%|█████▊    | 52/90 [00:07<00:05,  6.90it/s][A

 59%|█████▉    | 53/90 [00:07<00:05,  6.97it/s][A

 60%|██████    | 54/90 [00:07<00:05,  7.02it/s][A

 61%|██████    | 55/90 [00:07<00:04,  7.00it/s][A

 62%|██████▏   | 56/90 [00:08<00:04,  6.96it/s][A

 63%|██████▎   | 57/90 [00:08<00:04,  6.90it/s][A

 64%|██████▍   | 58/90 [00:08<00:04,  6.89it/s][A

 66%|██████▌   | 59/90 [00:08<00:04,  6.51it/s][A

 67%|██████▋   | 60/90 [00:08<00:04,  6.60it/s][A

 68%|██████▊   | 61/90 [00:08<00:04,  6.62it/s][A

 69%|██████▉   | 62/90 [00:08<00:04,  6.74it/s][A

 70%|███████   | 63/90 [00:09<00:04,  6.72it/s][A

 71%|███████   | 64/90 [00:09<00:03,  6.54it/s][A

 72%|███████▏  | 65/90 [00:09<00:03,  6.64it/s][A

 73%|███████▎  | 66/90 [00:09<00:03,  6.71it/s][A

 74%|███████▍  | 67/90 [00:09<00:03,  6.53it/s][A

 76%|███████▌  | 68/90 [00:09<00:03,  6.67it/s][A

 77%|███████▋  | 69/90 [00:09<00:03,  6.78it/s][A

 78%|███████▊  | 70/90 [00:10<00:02,  6.85it/s][A

 79%|███████▉  | 71/90 [00:10<00:02,  6.80it/s][A

 80%|████████  | 72/90 [00:10<00:02,  6.87it/s][A

 81%|████████  | 73/90 [00:10<00:02,  6.65it/s][A

 82%|████████▏ | 74/90 [00:10<00:02,  6.71it/s][A

 83%|████████▎ | 75/90 [00:10<00:02,  6.69it/s][A

 84%|████████▍ | 76/90 [00:11<00:02,  6.56it/s][A

 86%|████████▌ | 77/90 [00:11<00:01,  6.68it/s][A

 87%|████████▋ | 78/90 [00:11<00:01,  6.68it/s][A

 88%|████████▊ | 79/90 [00:11<00:01,  6.75it/s][A

 89%|████████▉ | 80/90 [00:11<00:01,  6.77it/s][A

 90%|█████████ | 81/90 [00:11<00:01,  6.84it/s][A

 91%|█████████ | 82/90 [00:11<00:01,  6.86it/s][A

 92%|█████████▏| 83/90 [00:12<00:01,  6.88it/s][A

 93%|█████████▎| 84/90 [00:12<00:00,  6.89it/s][A

 94%|█████████▍| 85/90 [00:12<00:00,  6.90it/s][A

 96%|█████████▌| 86/90 [00:12<00:00,  6.82it/s][A

 97%|█████████▋| 87/90 [00:12<00:00,  6.68it/s][A

 98%|█████████▊| 88/90 [00:12<00:00,  6.75it/s][A

 99%|█████████▉| 89/90 [00:12<00:00,  6.78it/s][A

100%|██████████| 90/90 [00:13<00:00,  6.83it/s][A
                                                 

                                               
[A{'eval_loss': 0.00275242212228477, 'eval_runtime': 13.2157, 'eval_samples_per_second': 13.62, 'eval_steps_per_second': 6.81, 'epoch': 4.99}

100%|██████████| 505/505 [32:55<00:00,  3.78s/it]

100%|██████████| 90/90 [00:13<00:00,  6.83it/s][A

                                               [A[INFO|trainer.py:2584] 2025-01-06 21:05:55,510 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)



                                                 
{'train_runtime': 1985.2012, 'train_samples_per_second': 4.073, 'train_steps_per_second': 0.254, 'train_loss': 0.11035776158960739, 'epoch': 4.99}

100%|██████████| 505/505 [32:55<00:00,  3.78s/it]
100%|██████████| 505/505 [32:55<00:00,  3.91s/it]
[INFO|trainer.py:3801] 2025-01-06 21:05:55,511 >> Saving model checkpoint to saves/qwen-14b-nl-e5/lora/sft
[INFO|configuration_utils.py:677] 2025-01-06 21:05:55,531 >> loading configuration file /mnt/sda/zzh/Qwen2.5-14B-Instruct/config.json
[INFO|configuration_utils.py:746] 2025-01-06 21:05:55,531 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 32768,
  "max_window_layers": 70,
  "model_type": "qwen2",
  "num_attention_heads": 40,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.46.1",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}

[INFO|tokenization_utils_base.py:2646] 2025-01-06 21:05:55,639 >> tokenizer config file saved in saves/qwen-14b-nl-e5/lora/sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2025-01-06 21:05:55,639 >> Special tokens file saved in saves/qwen-14b-nl-e5/lora/sft/special_tokens_map.json
***** train metrics *****
  epoch                    =      4.9938
  total_flos               = 227498860GF
  train_loss               =      0.1104
  train_runtime            =  0:33:05.20
  train_samples_per_second =       4.073
  train_steps_per_second   =       0.254
Figure saved at: saves/qwen-14b-nl-e5/lora/sft/training_loss.png
Figure saved at: saves/qwen-14b-nl-e5/lora/sft/training_eval_loss.png
[WARNING|2025-01-06 21:05:55] llamafactory.extras.ploting:162 >> No metric eval_accuracy to plot.
[INFO|trainer.py:4117] 2025-01-06 21:05:55,782 >> 
***** Running Evaluation *****
[INFO|trainer.py:4119] 2025-01-06 21:05:55,782 >>   Num examples = 180
[INFO|trainer.py:4122] 2025-01-06 21:05:55,782 >>   Batch size = 1

  0%|          | 0/90 [00:00<?, ?it/s]
  2%|▏         | 2/90 [00:00<00:06, 12.88it/s]
  4%|▍         | 4/90 [00:00<00:10,  8.49it/s]
  6%|▌         | 5/90 [00:00<00:10,  8.08it/s]
  7%|▋         | 6/90 [00:00<00:10,  7.73it/s]
  8%|▊         | 7/90 [00:00<00:11,  7.49it/s]
  9%|▉         | 8/90 [00:01<00:11,  7.36it/s]
 10%|█         | 9/90 [00:01<00:11,  7.21it/s]
 11%|█         | 10/90 [00:01<00:11,  7.12it/s]
 12%|█▏        | 11/90 [00:01<00:11,  6.98it/s]
 13%|█▎        | 12/90 [00:01<00:11,  6.72it/s]
 14%|█▍        | 13/90 [00:01<00:11,  6.78it/s]
 16%|█▌        | 14/90 [00:01<00:11,  6.85it/s]
 17%|█▋        | 15/90 [00:02<00:11,  6.78it/s]
 18%|█▊        | 16/90 [00:02<00:10,  6.86it/s]
 19%|█▉        | 17/90 [00:02<00:10,  6.84it/s]
 20%|██        | 18/90 [00:02<00:10,  6.81it/s]
 21%|██        | 19/90 [00:02<00:10,  6.85it/s]
 22%|██▏       | 20/90 [00:02<00:10,  6.88it/s]
 23%|██▎       | 21/90 [00:02<00:10,  6.89it/s]
 24%|██▍       | 22/90 [00:03<00:10,  6.69it/s]
 26%|██▌       | 23/90 [00:03<00:09,  6.81it/s]
 27%|██▋       | 24/90 [00:03<00:09,  6.82it/s]
 28%|██▊       | 25/90 [00:03<00:09,  6.67it/s]
 29%|██▉       | 26/90 [00:03<00:09,  6.55it/s]
 30%|███       | 27/90 [00:03<00:09,  6.81it/s]
 31%|███       | 28/90 [00:03<00:09,  6.66it/s]
 32%|███▏      | 29/90 [00:04<00:09,  6.52it/s]
 33%|███▎      | 30/90 [00:04<00:09,  6.62it/s]
 34%|███▍      | 31/90 [00:04<00:08,  6.73it/s]
 36%|███▌      | 32/90 [00:04<00:08,  6.59it/s]
 37%|███▋      | 33/90 [00:04<00:08,  6.73it/s]
 38%|███▊      | 34/90 [00:04<00:08,  6.77it/s]
 39%|███▉      | 35/90 [00:05<00:08,  6.82it/s]
 40%|████      | 36/90 [00:05<00:07,  6.85it/s]
 41%|████      | 37/90 [00:05<00:07,  6.93it/s]
 42%|████▏     | 38/90 [00:05<00:07,  6.93it/s]
 43%|████▎     | 39/90 [00:05<00:07,  6.93it/s]
 44%|████▍     | 40/90 [00:05<00:07,  6.93it/s]
 46%|████▌     | 41/90 [00:05<00:07,  6.90it/s]
 47%|████▋     | 42/90 [00:06<00:06,  6.89it/s]
 48%|████▊     | 43/90 [00:06<00:06,  6.91it/s]
 49%|████▉     | 44/90 [00:06<00:06,  6.94it/s]
 50%|█████     | 45/90 [00:06<00:06,  6.94it/s]
 51%|█████     | 46/90 [00:06<00:06,  6.92it/s]
 52%|█████▏    | 47/90 [00:06<00:06,  6.71it/s]
 53%|█████▎    | 48/90 [00:06<00:06,  6.82it/s]
 54%|█████▍    | 49/90 [00:07<00:05,  6.89it/s]
 56%|█████▌    | 50/90 [00:07<00:05,  6.95it/s]
 57%|█████▋    | 51/90 [00:07<00:05,  6.92it/s]
 58%|█████▊    | 52/90 [00:07<00:05,  6.89it/s]
 59%|█████▉    | 53/90 [00:07<00:05,  6.92it/s]
 60%|██████    | 54/90 [00:07<00:05,  6.97it/s]
 61%|██████    | 55/90 [00:07<00:05,  6.98it/s]
 62%|██████▏   | 56/90 [00:08<00:04,  6.98it/s]
 63%|██████▎   | 57/90 [00:08<00:04,  6.94it/s]
 64%|██████▍   | 58/90 [00:08<00:04,  6.94it/s]
 66%|██████▌   | 59/90 [00:08<00:04,  6.57it/s]
 67%|██████▋   | 60/90 [00:08<00:04,  6.68it/s]
 68%|██████▊   | 61/90 [00:08<00:04,  6.67it/s]
 69%|██████▉   | 62/90 [00:08<00:04,  6.80it/s]
 70%|███████   | 63/90 [00:09<00:03,  6.75it/s]
 71%|███████   | 64/90 [00:09<00:03,  6.62it/s]
 72%|███████▏  | 65/90 [00:09<00:03,  6.72it/s]
 73%|███████▎  | 66/90 [00:09<00:03,  6.77it/s]
 74%|███████▍  | 67/90 [00:09<00:03,  6.56it/s]
 76%|███████▌  | 68/90 [00:09<00:03,  6.68it/s]
 77%|███████▋  | 69/90 [00:09<00:03,  6.75it/s]
 78%|███████▊  | 70/90 [00:10<00:02,  6.81it/s]
 79%|███████▉  | 71/90 [00:10<00:02,  6.77it/s]
 80%|████████  | 72/90 [00:10<00:02,  6.82it/s]
 81%|████████  | 73/90 [00:10<00:02,  6.63it/s]
 82%|████████▏ | 74/90 [00:10<00:02,  6.70it/s]
 83%|████████▎ | 75/90 [00:10<00:02,  6.68it/s]
 84%|████████▍ | 76/90 [00:11<00:02,  6.56it/s]
 86%|████████▌ | 77/90 [00:11<00:01,  6.70it/s]
 87%|████████▋ | 78/90 [00:11<00:01,  6.69it/s]
 88%|████████▊ | 79/90 [00:11<00:01,  6.78it/s]
 89%|████████▉ | 80/90 [00:11<00:01,  6.79it/s]
 90%|█████████ | 81/90 [00:11<00:01,  6.82it/s]
 91%|█████████ | 82/90 [00:11<00:01,  6.83it/s]
 92%|█████████▏| 83/90 [00:12<00:01,  6.83it/s]
 93%|█████████▎| 84/90 [00:12<00:00,  6.85it/s]
 94%|█████████▍| 85/90 [00:12<00:00,  6.86it/s]
 96%|█████████▌| 86/90 [00:12<00:00,  6.80it/s]
 97%|█████████▋| 87/90 [00:12<00:00,  6.63it/s]
 98%|█████████▊| 88/90 [00:12<00:00,  6.72it/s]
 99%|█████████▉| 89/90 [00:12<00:00,  6.76it/s]
100%|██████████| 90/90 [00:13<00:00,  6.82it/s]
100%|██████████| 90/90 [00:13<00:00,  6.87it/s]
***** eval metrics *****
  epoch                   =     4.9938
  eval_loss               =     0.0028
  eval_runtime            = 0:00:13.23
  eval_samples_per_second =     13.596
  eval_steps_per_second   =      6.798
[INFO|modelcard.py:449] 2025-01-06 21:06:09,022 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
[rank0]:[W106 21:06:09.864358536 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
